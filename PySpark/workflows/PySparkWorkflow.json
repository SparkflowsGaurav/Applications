{  "name": "PySpark Workflow",  "uuid": "dba70d8b-5fb8-4bfa-8f80-8886060e195e",  "category": "-",  "description": "-",  "parameters": "-",  "nodes": [    {      "id": "1",      "name": "ReadCSV",      "description": "It reads in CSV files and creates a DataFrame from it",      "details": "",      "examples": "",      "type": "dataset",      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",      "x": "58.8021px",      "y": "176.948px",      "hint": "Whenever the file is changed, Refresh the Schema",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "path",          "value": "data/housing.csv",          "widget": "textfield",          "title": "Path",          "description": "Path of the Text file/directory",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "separator",          "value": ",",          "widget": "textfield",          "title": "Separator",          "description": "CSV Separator",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "header",          "value": "true",          "widget": "array",          "title": "Header",          "description": "Does the file have a header row",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropMalformed",          "value": "false",          "widget": "array",          "title": "Drop Malformed",          "description": "Whether to drop Malformed records or error",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColNames",          "value": "[\"id\",\"price\",\"lotsize\",\"bedrooms\",\"bathrms\",\"stories\",\"driveway\",\"recroom\",\"fullbase\",\"gashw\",\"airco\",\"garagepl\",\"prefarea\"]",          "widget": "schema_col_names",          "title": "Column Names for the CSV",          "description": "New Output Columns of the SQL",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColTypes",          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",          "widget": "schema_col_types",          "title": "Column Types for the CSV",          "description": "Data Type of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColFormats",          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",          "widget": "schema_col_formats",          "title": "Column Formats for the CSV",          "description": "Format of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "2",      "name": "PrintNRows",      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",      "x": "280.122px",      "y": "173.285px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "title",          "value": "Row Values",          "widget": "textfield",          "title": "Title",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "n",          "value": "10",          "widget": "textfield",          "title": "Num Rows to Print",          "description": "number of rows to be printed",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "3",      "name": "PySpark",      "description": "This node runs any given PySpark code. The input dataframe is passed in the variable inDF. The output dataframe is passed back by registering it as a temporary table.",      "details": "",      "examples": "",      "type": "pyspark",      "nodeClass": "fire.nodes.etl.NodePySpark",      "x": "509.781px",      "y": "63.9688px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "code",          "value": "from pyspark.sql.types import StringType\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import *\nfrom fire.workflowcontext import *\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):\n  house_type_udf = udf(lambda bedrooms: \"big house\" if int(bedrooms) >2 else \"small house\", StringType())\n  filetr_df = inDF.select(\"id\", \"price\", \"lotsize\", \"bedrooms\")\n  outDF = filetr_df.withColumn(\"house_type\", house_type_udf(filetr_df.bedrooms))\n  return outDF",          "widget": "textarea_large",          "type": "python",          "title": "PySpark",          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "schema",          "value": "",          "widget": "tab",          "title": "Schema",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColNames",          "value": "[\"id\",\"price\",\"lotsize\",\"bedrooms\",\"house_type\"]",          "widget": "schema_col_names",          "title": "Column Names for the CSV",          "description": "New Output Columns of the SQL",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColTypes",          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",          "widget": "schema_col_types",          "title": "Column Types for the CSV",          "description": "Data Type of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColFormats",          "value": "[\"\",\"\",\"\",\"\",\"\"]",          "widget": "schema_col_formats",          "title": "Column Formats for the CSV",          "description": "Format of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "pyspark"    },    {      "id": "5",      "name": "PrintNRows",      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",      "x": "726.819px",      "y": "62.9757px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "title",          "value": "Row Values",          "widget": "textfield",          "title": "Title",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "n",          "value": "10",          "widget": "textfield",          "title": "Num Rows to Print",          "description": "number of rows to be printed",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "6",      "name": "PySpark",      "description": "This node runs any given PySpark code. The input dataframe is passed in the variable inDF. The output dataframe is passed back by registering it as a temporary table.",      "details": "",      "examples": "",      "type": "pyspark",      "nodeClass": "fire.nodes.etl.NodePySpark",      "x": "520.156px",      "y": "246.663px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "code",          "value": "from pyspark.sql.types import StringType\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import *\nfrom fire.workflowcontext import *\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):\n  def multiply_func(a, b):\n    return a * b\n        \n  # multiply = pandas_udf(multiply_func, returnType=LongType())\n      \n  return inDF      ",          "widget": "textarea_large",          "type": "python",          "title": "PySpark",          "description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "schema",          "value": "",          "widget": "tab",          "title": "Schema",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColNames",          "value": "[\"id\",\"price\",\"lotsize\",\"bedrooms\",\"bathrms\",\"stories\",\"driveway\",\"recroom\",\"fullbase\",\"gashw\",\"airco\",\"garagepl\",\"prefarea\"]",          "widget": "schema_col_names",          "title": "Column Names for the CSV",          "description": "New Output Columns of the SQL",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColTypes",          "value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",          "widget": "schema_col_types",          "title": "Column Types for the CSV",          "description": "Data Type of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColFormats",          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",          "widget": "schema_col_formats",          "title": "Column Formats for the CSV",          "description": "Format of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "pyspark"    },    {      "id": "7",      "name": "PrintNRows",      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",      "x": "735.16px",      "y": "241.649px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "title",          "value": "Row Values",          "widget": "textfield",          "title": "Title",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "n",          "value": "10",          "widget": "textfield",          "title": "Num Rows to Print",          "description": "number of rows to be printed",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    }  ],  "edges": [    {      "source": "1",      "target": "2",      "id": 1    },    {      "source": "2",      "target": "3",      "id": 2    },    {      "source": "3",      "target": "5",      "id": 3    },    {      "source": "2",      "target": "6",      "id": 4    },    {      "source": "6",      "target": "7",      "id": 5    }  ],  "dataSetDetails": [],  "engine": "pyspark"}
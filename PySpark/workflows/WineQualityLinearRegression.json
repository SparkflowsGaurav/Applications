{	"name": "Wine Quality Linear Regression",	"uuid": "a69f639d-fc23-4733-9383-fc0f4a57ced4",	"category": "-",	"description": "-",	"parameters": "-",	"nodes": [		{			"id": "1",			"name": "ReadCSV",			"description": "It reads in CSV files and creates a DataFrame from it",			"details": "This node reads CSV files and creates a DataFrame from it.<br>",			"examples": "",			"type": "dataset",			"nodeClass": "fire.nodes.dataset.NodeDatasetCSV",			"x": "64.5469px",			"y": "154.68px",			"hint": "Whenever the file is changed, Refresh the Schema",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "path",					"value": "data/winequality.csv",					"widget": "textfield",					"title": "Path",					"description": "Path of the Text file/directory",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "separator",					"value": ",",					"widget": "textfield",					"title": "Separator",					"description": "CSV Separator",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "header",					"value": "true",					"widget": "array",					"title": "Header",					"description": "Does the file have a header row",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dropMalformed",					"value": "true",					"widget": "array",					"title": "Drop Malformed",					"description": "Whether to drop Malformed records or error",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]",					"widget": "schema_col_names",					"title": "Column Names for the CSV",					"description": "New Output Columns of the SQL",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",					"widget": "schema_col_types",					"title": "Column Types for the CSV",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Column Formats for the CSV",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "2",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "299.852px",			"y": "155.012px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "10",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "displayDataType",					"value": "true",					"widget": "array",					"title": "Display Data Type",					"description": "If true display rows DataType",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "3",			"name": "PySpark",			"description": "This node runs any given PySpark code. The input dataframe is passed in the variable inDF. The output dataframe is passed back by registering it as a temporary table.",			"details": "This node receives receives an input pyspark dataframe in function called myfn.<br>\n<br>\nFinally the pyspark/python code returns the pyspark daframe.<br>",			"examples": "<h2>Format Examples</h2>\n<br>\nInput Schema: id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> add the house_type column</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\nfrom fire.workflowcontext import *<br>\n<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\nhouse_type_udf = udf(lambda bedrooms: \"big house\" if int(bedrooms) >2 else \"small house\", StringType())<br>\nfiletr_df = inDF.select(\"id\", \"price\", \"lotsize\", \"bedrooms\")<br>\noutDF = filetr_df.withColumn(\"house_type\", house_type_udf(filetr_df.bedrooms))<br>\nreturn outDF<br>\n<br>\n<h4> using pandas dataframe</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\n<br>\nfrom fire.workflowcontext import *<br>\n<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\n# Convert the Spark DataFrame to a Pandas DataFrame<br>\npdf = inDF.select(\"*\").toPandas()<br>\n<br>\nworkflowContext.outStr(id, \"Outputting Pandas Dataframe\",\"\")<br>\nworkflowContext.outPandasDataframe(id, \"Pandas DataFrame\", pdf, 10)<br>\n<br>\n# Create a Spark DataFrame from a Pandas DataFrame<br>\ndf = spark.createDataFrame(pdf)<br>\n<br>\nreturn df<br>\n<br>\n<h4> numpy 2d array to pandas dataframe & pandas dataframe to spark dataframe</h4>\n<br>\nfrom pyspark.sql.types import StringType<br>\nfrom pyspark.sql.functions import *<br>\nfrom pyspark.sql import *<br>\nimport numpy as np<br>\nimport pandas as pd<br>\n<br>\nfrom fire.workflowcontext import *<br>\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):<br>\n# Create the numpy 2d array<br>\nexample_array = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])<br>\n# Convert to Pandas Dataframe<br>\npandas_dataframe = pd.DataFrame(example_array, columns=['a', 'b', 'c', 'd'])<br>\n# Convert Pandas Dataframe to Spark Dataframe<br>\nspark_dataframe = spark.createDataFrame(pandas_dataframe)<br>\nreturn spark_dataframe<br>",			"type": "pyspark",			"nodeClass": "fire.nodes.etl.NodePySpark",			"x": "538.586px",			"y": "157.777px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "code",					"value": "from pyspark.sql.types import StringType\nfrom pyspark.sql.functions import *\nfrom pyspark.sql import *\n\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom joblib import dump, load\n\nfrom fire.workflowcontext import *\n\ndef myfn(spark: SparkSession, workflowContext: WorkflowContext, id: int, inDF: DataFrame, cust_dict):\n  # Convert the Spark DataFrame to a Pandas DataFrame using Arrow\n  dataset = inDF.select(\"*\").toPandas()\n  \n  print(dataset.head)\n  print(dataset.shape)\n  print(dataset.describe())\n  dataset = dataset.fillna(method='ffill')\n    \n  X = dataset[\n        ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide',\n         'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']].values\n  print(X)\n\n  y = dataset['quality'].values\n  print(y)\n\n  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n  # There are three steps to model something with sklearn\n  # 1. Set up the model\n  model = LinearRegression()\n  # 2. Use fit\n  ft = model.fit(X_train, y_train)\n  print(ft)\n  # 3. Check the score\n  scr = model.score(X_test, y_test)\n  workflowContext.outStr(id, \"Model Score : \" + str(scr),\"\")\n\n  # 4. Print model\n  workflowContext.outStr(id, \"Model Coeffient : \" + str(model.coef_),\"\")\n  workflowContext.outStr(id, \"Model Intercept : \" + str(model.intercept_),\"\")\n\n  # 5. Predict test data\n  y_pred = model.predict(X_test)\n\n  # 6. See difference between actual and predicted value\n  df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n  df1 = df.head(25)\n  workflowContext.outPandasDataframe(id, \"Actual - Predicted : \", df1, 10, True)\n\n  # 7. Evaluate the performance\n  workflowContext.outStr(id, \"Mean Absolute Error:\" + str(metrics.mean_absolute_error(y_test, y_pred)),\"\")\n  workflowContext.outStr(id, \"Mean Squared Error:\" + str(metrics.mean_squared_error(y_test, y_pred)),\"\")\n  workflowContext.outStr(id, \"Root Mean Squared Error:\" + str(np.sqrt(metrics.mean_squared_error(y_test, y_pred))),\"\")\n    \n  return inDF\n    \n",					"widget": "textarea_large",					"type": "python",					"title": "PySpark",					"description": "PySpark code to be run. Input dataframe : \"inDF\", SparkContext : \"sc\", SQLContext : \"sqlContext\",  Output/Result dataframe should be registered as a temporary table - df.registerTempTable(\"outDF\")",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "schema",					"value": "",					"widget": "tab",					"title": "Schema",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"fixed_acidity\",\"volatile_acidity\",\"citric_acid\",\"residual_sugar\",\"chlorides\",\"free_sulfur_dioxide\",\"total_sulfur_dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]",					"widget": "schema_col_names",					"title": "Column Names for the CSV",					"description": "New Output Columns of the SQL",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",					"widget": "schema_col_types",					"title": "Column Types for the CSV",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Column Formats for the CSV",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "pyspark"		},		{			"id": "5",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "765.641px",			"y": "157.793px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "10",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "displayDataType",					"value": "true",					"widget": "array",					"title": "Display Data Type",					"description": "If true display rows DataType",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "6",			"name": "Notes",			"description": "Allows capturing Notes on the Workflow",			"details": "",			"examples": "",			"type": "doc",			"nodeClass": "fire.nodes.doc.NodeDocLarge",			"x": "604px",			"y": "421.5px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "comment",					"value": "<p>fdsafdsa</p>",					"widget": "textarea_rich",					"title": "Comment",					"description": "Comments for the Workflow",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		}	],	"edges": [		{			"source": "1",			"target": "2",			"id": 1		},		{			"source": "2",			"target": "3",			"id": 2		},		{			"source": "3",			"target": "5",			"id": 3		}	],	"dataSetDetails": [],	"engine": "pyspark"}
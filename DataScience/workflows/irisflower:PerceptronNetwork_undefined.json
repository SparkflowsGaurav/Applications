{	"name": "iris flower : Perceptron Network",	"uuid": "9391bf62-7435-496a-9485-c65f9f2c4f69",	"category": "Prediction",	"description": "Predicts Iris using Multi Layer Perceptron",	"nodes": [		{			"id": "1",			"name": "CSV",			"description": "It reads in CSV files and creates a DataFrame from it",			"details": "This node reads CSV files and creates a DataFrame from it.<br>",			"examples": "",			"type": "dataset",			"nodeClass": "fire.nodes.dataset.NodeDatasetCSV",			"x": "21px",			"y": "288.625px",			"hint": "Whenever the file is changed, Refresh the Schema",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "path",					"value": "data/iris.data.txt",					"widget": "textfield",					"title": "Path",					"description": "Path of the Text file/directory",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "separator",					"value": ",",					"widget": "textfield",					"title": "Separator",					"description": "CSV Separator",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "header",					"value": "false",					"widget": "array",					"title": "Header",					"description": "Does the file have a header row",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dropSpecialCharacterInColumnName",					"value": "true",					"widget": "array",					"title": "Drop Special Character In ColumnName",					"description": "Drop the SpecialCharacter and Space in Column Name.",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dropMalformed",					"value": "false",					"widget": "array",					"title": "Drop Malformed",					"description": "Whether to drop Malformed records or error",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"C0\",\"C1\",\"C2\",\"C3\",\"C4\"]",					"widget": "schema_col_names",					"title": "Column Names for the CSV",					"description": "New Output Columns of the SQL",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"STRING\"]",					"widget": "schema_col_types",					"title": "Column Types for the CSV",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Column Formats for the CSV",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "3",			"name": "VectorAssembler",			"description": "Merges multiple columns into a vector column",			"details": "VectorAssembler is a transformer that combines a given list of columns into a single vector column. <br>\nIt is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. <br>\nVectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.<br>\n<br>\nMore details are available at:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorAssembler<br>\nimport org.apache.spark.ml.linalg.Vectors<br>\n<br>\nval dataset = spark.createDataFrame(<br>\n  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))<br>\n).toDF(\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\")<br>\n<br>\nval assembler = new VectorAssembler()<br>\n  .setInputCols(Array(\"hour\", \"mobile\", \"userFeatures\"))<br>\n  .setOutputCol(\"features\")<br>\n<br>\nval output = assembler.transform(dataset)<br>\nprintln(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")<br>\noutput.select(\"features\", \"clicked\").show(false)<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeVectorAssembler",			"x": "150px",			"y": "289.625px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"C0\",\"C1\",\"C2\",\"C3\"]",					"widget": "variables",					"title": "Input Columns",					"description": "Input column of type - all numeric, boolean and vector",					"datatypes": [						"integer",						"long",						"double",						"float",						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "features",					"widget": "textfield",					"title": "Output Column",					"description": "Output column name",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "handleInvalid",					"value": "error",					"widget": "array",					"title": "HandleInvalid",					"description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",					"optionsArray": [						"error",						"skip",						"keep"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "5",			"name": "StringIndexer",			"description": "StringIndexer encodes a string column of labels to a column of label indices",			"details": "StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0.<br>\nIf the input column is numeric, we cast it to string and index the string values.<br>\n                                                                                                  <br>\nMore at Spark MLlib/ML docs page : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#stringindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#stringindexer</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#stringindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#stringindexer</a></h2>\n<br>\nimport org.apache.spark.ml.feature.StringIndexer<br>\n<br>\nval df = spark.createDataFrame(<br>\n  Seq((0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\"))<br>\n).toDF(\"id\", \"category\")<br>\n<br>\nval indexer = new StringIndexer()<br>\n  .setInputCol(\"category\")<br>\n  .setOutputCol(\"categoryIndex\")<br>\n<br>\nval indexed = indexer.fit(df).transform(df)<br>\nindexed.show()<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeStringIndexer",			"x": "275.25px",			"y": "288.844px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "handleInvalid",					"value": "error",					"widget": "array",					"title": "Handle Invalid",					"description": "Invalid entries to be skipped or thrown error",					"optionsArray": [						"skip",						"error"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"C4\"]",					"widget": "variables_list_select",					"title": "Input Columns",					"description": "Input columns for encoding",					"datatypes": [						"string"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCols",					"value": "[\"label\"]",					"widget": "variables_list_textfield",					"title": "Output Columns",					"description": "Output columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "7",			"name": "VectorIndexer",			"description": "Vector Indexer indexes categorical features inside of a Vector. It decides which features are categorical and converts them to category indices. The decision is based on the number of distinct values of a feature.",			"details": "VectorIndexer helps index categorical features in datasets of Vectors. It can both automatically decide which features are categorical and convert original values to category indices.<br>\nMore details are available at: <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorIndexer<br>\n<br>\nval data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\nval indexer = new VectorIndexer()<br>\n  .setInputCol(\"features\")<br>\n  .setOutputCol(\"indexed\")<br>\n  .setMaxCategories(10)<br>\n<br>\nval indexerModel = indexer.fit(data)<br>\n<br>\nval categoricalFeatures: Set[Int] = indexerModel.categoryMaps.keys.toSet<br>\nprintln(s\"Chose ${categoricalFeatures.size} categorical features: \" +<br>\n  categoricalFeatures.mkString(\", \"))<br>\n<br>\n// Create new column \"indexed\" with categorical values transformed to indices<br>\nval indexedData = indexerModel.transform(data)<br>\nindexedData.show()<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeVectorIndexer",			"x": "406px",			"y": "287.625px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCol",					"value": "features",					"widget": "variable",					"title": "Input Column",					"description": "The Input column name",					"datatypes": [						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "indexedFeatures",					"widget": "textfield",					"title": "Output Column",					"description": "Output column name",					"datatypes": [						"vectorudt"					],					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxCategories",					"value": "10",					"widget": "textfield",					"title": "Maximum Categories",					"description": "Threshold for the number of values a categorical feature can take. If a feature is found to have > maxCategories values, then it is declared continuous. Must be >= 2",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "8",			"name": "Split",			"description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data. For example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).",			"details": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data.<br>\n<br>\nFor example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).<br>\n<br>\nThe split node can be used for splitting the DataFrame for training and test datasets used in Machine Learning.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.ml.NodeSplit",			"x": "526.219px",			"y": "287.875px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "fraction1",					"value": ".7",					"widget": "textfield",					"title": "Fraction 1",					"description": "Fraction to be used for Splitting the DataFrame into two. The first DataFrame would go to the lower edge output. The other would go to the higher edge output.",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "9",			"name": "MultiLayerPerceptron",			"description": "It supports creation of full connected neural network.",			"details": "Multilayer perceptron classifier (MLPC) is a classifier based on the feedforward artificial neural network. <br>\nMLPC consists of multiple layers of nodes. Each layer is fully connected to the next layer in the network. Nodes in the input layer represent the input data.<br>",			"examples": "Below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier</a><br>\n<br>\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier<br>\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator<br>\n<br>\n// Load the data stored in LIBSVM format as a DataFrame.<br>\nval data = spark.read.format(\"libsvm\")<br>\n  .load(\"data/mllib/sample_multiclass_classification_data.txt\")<br>\n<br>\n// Split the data into train and test<br>\nval splits = data.randomSplit(Array(0.6, 0.4), seed = 1234L)<br>\nval train = splits(0)<br>\nval test = splits(1)<br>\n<br>\n// specify layers for the neural network:<br>\n// input layer of size 4 (features), two intermediate of size 5 and 4<br>\n// and output of size 3 (classes)<br>\nval layers = Array[Int](4, 5, 4, 3)<br>\n<br>\n// create the trainer and set its parameters<br>\nval trainer = new MultilayerPerceptronClassifier()<br>\n  .setLayers(layers)<br>\n  .setBlockSize(128)<br>\n  .setSeed(1234L)<br>\n  .setMaxIter(100)<br>\n<br>\n// train the model<br>\nval model = trainer.fit(train)<br>\n<br>\n// compute accuracy on the test set<br>\nval result = model.transform(test)<br>\nval predictionAndLabels = result.select(\"prediction\", \"label\")<br>\nval evaluator = new MulticlassClassificationEvaluator()<br>\n  .setMetricName(\"accuracy\")<br>\n<br>\nprintln(s\"Test set accuracy = ${evaluator.evaluate(predictionAndLabels)}\")<br>",			"type": "ml-estimator",			"nodeClass": "fire.nodes.ml.NodeMultilayerPerceptron",			"x": "656.219px",			"y": "107.844px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "featuresCol",					"value": "indexedFeatures",					"widget": "variable",					"title": "Features Column",					"description": "Features column of type vectorUDT for model fitting",					"datatypes": [						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "label",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"value": "",					"widget": "textfield",					"title": "Prediction Column",					"description": "The prediction column created during model scoring.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "layers",					"value": "4,5,5,3",					"widget": "textfield",					"title": "Layers - comma separated list of integers",					"description": "The integer array specifying the number of activation units in each layer",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxIter",					"value": "100",					"widget": "textfield",					"title": "Max number of iterations",					"description": "Number of iterations to train the Neural network",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "blockSize",					"value": "128",					"widget": "textfield",					"title": "Block Size",					"description": "Block size",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "seed",					"value": "123",					"widget": "textfield",					"title": "Seed",					"description": "The initial seed to initialise the neural network.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "tol",					"value": "1e-6",					"widget": "textfield",					"title": "Tol",					"description": "",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "solver",					"value": "l-bfgs",					"widget": "textfield",					"title": "Solver",					"description": "solver",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "stepSize",					"value": "0.03",					"widget": "textfield",					"title": "Step Size",					"description": "Step size",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "10",			"name": "Predict",			"description": "Predict node takes in a DataFrame and Model and makes predictions",			"details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",			"examples": "",			"type": "ml-predict",			"nodeClass": "fire.nodes.ml.NodePredict",			"x": "660.25px",			"y": "288.875px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "11",			"name": "MulticlassClassificationEvaluator",			"description": "Evaluator for multiclass classification, which expects two input columns: score and label.",			"details": "Evaluator for multiclass classification, which expects two input columns: score and label.<br>\n<br>\nMore at Spark MLlib/ML docs page :<a href=\"https://spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification</a><br>",			"examples": "<h2>Below example is available at : <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification</a></h2>\n<br>\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS<br>\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics<br>\nimport org.apache.spark.mllib.regression.LabeledPoint<br>\nimport org.apache.spark.mllib.util.MLUtils<br>\n<br>\n// Load training data in LIBSVM format<br>\nval data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_multiclass_classification_data.txt\")<br>\n<br>\n// Split data into training (60%) and test (40%)<br>\nval Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)<br>\ntraining.cache()<br>\n<br>\n// Run training algorithm to build the model<br>\nval model = new LogisticRegressionWithLBFGS()<br>\n  .setNumClasses(3)<br>\n  .run(training)<br>\n<br>\n// Compute raw scores on the test set<br>\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =><br>\n  val prediction = model.predict(features)<br>\n  (prediction, label)<br>\n}<br>\n<br>\n// Instantiate metrics object<br>\nval metrics = new MulticlassMetrics(predictionAndLabels)<br>\n<br>\n// Confusion matrix<br>\nprintln(\"Confusion matrix:\")<br>\nprintln(metrics.confusionMatrix)<br>\n<br>\n// Overall Statistics<br>\nval accuracy = metrics.accuracy<br>\nprintln(\"Summary Statistics\")<br>\nprintln(s\"Accuracy = $accuracy\")<br>\n<br>\n// Precision by label<br>\nval labels = metrics.labels<br>\nlabels.foreach { l =><br>\n  println(s\"Precision($l) = \" + metrics.precision(l))<br>\n}<br>\n<br>\n// Recall by label<br>\nlabels.foreach { l =><br>\n  println(s\"Recall($l) = \" + metrics.recall(l))<br>\n}<br>\n<br>\n// False positive rate by label<br>\nlabels.foreach { l =><br>\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))<br>\n}<br>\n<br>\n// F-measure by label<br>\nlabels.foreach { l =><br>\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))<br>\n}<br>\n<br>\n// Weighted stats<br>\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")<br>\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")<br>\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")<br>\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")<br>",			"type": "ml-evaluator",			"nodeClass": "fire.nodes.ml.NodeMulticlassClassificationEvaluator",			"x": "823.219px",			"y": "284.875px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "label",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting.",					"datatypes": [						"double"					],					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"value": "prediction",					"widget": "variable",					"title": "Prediction Column",					"description": "The prediction column.",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "metricName",					"value": "f1",					"widget": "array",					"title": "Metric Name",					"description": "The metric used in evaluation.",					"optionsArray": [						"f1",						"accuracy",						"weightedPrecision",						"weightedRecall"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "12",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "This node is used to print incoming dataset.<br>\n<br>\nNumber of rows that needs to be printed can be configured in the node.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "660.203px",			"y": "436.312px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "100",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "displayDataType",					"value": "true",					"widget": "array",					"title": "Display Data Type",					"description": "If true display rows DataType",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "13",			"name": "Sticky Note",			"description": "Allows capturing Notes on the Workflow",			"details": "",			"examples": "",			"type": "sticky",			"nodeClass": "fire.nodes.doc.NodeStickyNote",			"x": "71px",			"y": "67px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "bgColor",					"value": "blue",					"widget": "textfield",					"title": "Bg Color",					"description": "Background of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "width",					"value": "476px",					"widget": "textfield",					"title": "Width",					"description": "Width of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "height",					"value": "59px",					"widget": "textfield",					"title": "Height",					"description": "Height of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "comment",					"value": "<h4><span style=\"color: rgb(0, 0, 0);\">IRIS Classification Using </span>Multilayer perceptron classifier</h4>",					"widget": "textarea_rich",					"title": "Comment",					"description": "Comments for the Workflow",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		}	],	"edges": [		{			"source": "1",			"target": "3",			"id": 1		},		{			"source": "3",			"target": "5",			"id": 2		},		{			"source": "5",			"target": "7",			"id": 3		},		{			"source": "7",			"target": "8",			"id": 4		},		{			"source": "8",			"target": "9",			"id": 5		},		{			"source": "8",			"target": "10",			"id": 6		},		{			"source": "9",			"target": "10",			"id": 7		},		{			"source": "10",			"target": "11",			"id": 8		},		{			"source": "10",			"target": "12",			"id": 9		}	],	"dataSetDetails": [],	"engine": "scala"}
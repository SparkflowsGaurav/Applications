{  "name": "Patient diabetic or not",  "uuid": "b719d0eb-7812-41ee-b680-9f6e6241f59e",  "category": "Prediction - Classification",  "description": "Predict if a patient will be diabetic or not",  "parameters": "-",  "nodes": [    {      "id": "1",      "name": "ReadCSV",      "description": "It reads in CSV files and creates a DataFrame from it",      "details": "",      "examples": "",      "type": "dataset",      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",      "x": "120.703px",      "y": "73.3438px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "path",          "value": "data/diabetes.csv",          "widget": "textfield",          "title": "Path",          "description": "Path of the Text file/directory",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "separator",          "value": ",",          "widget": "textfield",          "title": "Separator",          "description": "CSV Separator",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "header",          "value": "true",          "widget": "array",          "title": "Header",          "description": "Does the file have a header row",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropMalformed",          "value": "true",          "widget": "array",          "title": "Drop Malformed",          "description": "Whether to drop Malformed records or error",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColNames",          "value": "[\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\",\"Outcome\"]",          "widget": "schema_col_names",          "title": "Column Names for the CSV",          "description": "New Output Columns of the SQL",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColTypes",          "value": "[\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\"]",          "widget": "schema_col_types",          "title": "Column Types for the CSV",          "description": "Data Type of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColFormats",          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",          "widget": "schema_col_formats",          "title": "Column Formats for the CSV",          "description": "Format of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "2",      "name": "DropRowsWithNull",      "description": "This node creates a new DataFrame by dropping rows containing null values",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNull",      "x": "286.984px",      "y": "72.6094px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "3",      "name": "RowFilter",      "description": "This node creates a new DataFrame containing only rows satisfying given condition",      "details": "This node creates a new DataFrame containing only rows satisfying the given condition.<br>\n<br>\n<h2>Examples of Conditional Expression</h2>\n<br>\ncol1 > 5 AND col2 > 3<br>\n<br>\nname is not NULL<br>\n<br>\nname is NULL<br>\n<br>\nusd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100<br>\n<br>\ndatetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)<br>\n<br>\ndatetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'<br>",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeRowFilter",      "x": "291.203px",      "y": "272.875px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "conditionExpr",          "value": "SkinThickness!=0",          "widget": "textarea_small",          "title": "Conditional Expression",          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "4",      "name": "RowFilter",      "description": "This node creates a new DataFrame containing only rows satisfying given condition",      "details": "This node creates a new DataFrame containing only rows satisfying the given condition.<br>\n<br>\n<h2>Examples of Conditional Expression</h2>\n<br>\ncol1 > 5 AND col2 > 3<br>\n<br>\nname is not NULL<br>\n<br>\nname is NULL<br>\n<br>\nusd_pledged_real > 0 and (category = \"Narrative Film\" or category == \"Music\") and goal > 100<br>\n<br>\ndatetime > '2011-01-01 00:00:00.0'     (datetime column is of type timestamp)<br>\n<br>\ndatetime > '2011-01-01 00:00:00.0' and datetime < '2016-01-01 00:00:00.0'<br>",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeRowFilter",      "x": "487.484px",      "y": "273.125px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "conditionExpr",          "value": "Insulin!=0",          "widget": "textarea_small",          "title": "Conditional Expression",          "description": "The filtering condition. Rows not satisfying given condition will be excluded from output DataFrame. eg: usd_pledged_real > 0 and (category = 1 or category == 2) and goal > 100",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "5",      "name": "PrintNRows",      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",      "x": "1233.97px",      "y": "395.625px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "title",          "value": "Row Values",          "widget": "textfield",          "title": "Title",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "n",          "value": "10",          "widget": "textfield",          "title": "Num Rows to Print",          "description": "number of rows to be printed",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "6",      "name": "LogisticRegression",      "description": "Logistic regression. Currently, this class only supports binary classification.",      "details": "Logistic regression is a popular method to predict a categorical response. <br>\n<br>\nIt is a special case of Generalized Linear models that predicts the probability of the outcomes. <br>\nIn spark.ml logistic regression can be used to predict a binary outcome by using binomial logistic regression, or it can be used to predict a multiclass outcome by using multinomial logistic regression.<br>\n<br>\nMore details are available at : <a href=\"https://spark.apache.org/docs/2.3.0/ml-classification-regression.html#logistic-regression\" target=\"_blank\">spark.apache.org/docs/2.3.0/ml-classification-regression.html#logistic-regression</a><br>",      "examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.3.0/ml-classification-regression.html#logistic-regression\" target=\"_blank\">spark.apache.org/docs/2.3.0/ml-classification-regression.html#logistic-regression</a></h2>\n<br>\n<br>\nimport org.apache.spark.ml.classification.LogisticRegression<br>\n<br>\n// Load training data<br>\nval training = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\nval lr = new LogisticRegression()<br>\n  .setMaxIter(10)<br>\n  .setRegParam(0.3)<br>\n  .setElasticNetParam(0.8)<br>\n<br>\n// Fit the model<br>\nval lrModel = lr.fit(training)<br>\n<br>\n// Print the coefficients and intercept for logistic regression<br>\nprintln(s\"Coefficients: ${lrModel.coefficients} Intercept: ${lrModel.intercept}\")<br>\n<br>\n// We can also use the multinomial family for binary classification<br>\nval mlr = new LogisticRegression()<br>\n  .setMaxIter(10)<br>\n  .setRegParam(0.3)<br>\n  .setElasticNetParam(0.8)<br>\n  .setFamily(\"multinomial\")<br>\n<br>\nval mlrModel = mlr.fit(training)<br>\n<br>\n// Print the coefficients and intercepts for logistic regression with multinomial family<br>\nprintln(s\"Multinomial coefficients: ${mlrModel.coefficientMatrix}\")<br>\nprintln(s\"Multinomial intercepts: ${mlrModel.interceptVector}\")<br>",      "type": "ml-estimator",      "nodeClass": "fire.nodes.ml.NodeLogisticRegression",      "x": "1050.72px",      "y": "112.344px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "featuresCol",          "value": "feature_vector",          "widget": "variable",          "title": "Features Column",          "description": "Features column of type vectorUDT for model fitting",          "datatypes": [            "vectorudt"          ],          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "labelCol",          "value": "Outcome",          "widget": "variable",          "title": "Label Column",          "description": "The label column for model fitting",          "datatypes": [            "double"          ],          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "predictionCol",          "value": "",          "widget": "textfield",          "title": "Prediction Column",          "description": "The prediction column created during model scoring",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxIter",          "value": "100",          "widget": "textfield",          "title": "Maximum Iterations",          "description": "Maximum number of iterations (>= 0)",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "fitIntercept",          "value": "true",          "widget": "array",          "title": "Fit Intercept",          "description": "Whether to fit an intercept term",          "datatypes": [            "boolean"          ],          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "regParam",          "value": "0.0",          "widget": "textfield",          "title": "Regularization Param",          "description": "The regularization parameter",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "standardization",          "value": "true",          "widget": "array",          "title": "Standardization",          "description": "Whether to standardize the training features before fitting the model",          "datatypes": [            "boolean"          ],          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "threshold",          "value": "0.5",          "widget": "textfield",          "title": "Threshold",          "description": "The threshold in binary classification prediction",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "tol",          "value": "1E-6",          "widget": "textfield",          "title": "Tolerance",          "description": "The convergence tolerance for iterative algorithms",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "elasticNetParam",          "value": "0.0",          "widget": "textfield",          "title": "ElasticNet Param",          "description": "The ElasticNet mixing parameter. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "weightCol",          "value": "",          "widget": "textfield",          "title": "Weight Column",          "description": "If the 'weight column' is not specified, all instances are treated equally with a weight 1.0",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "gridSearch",          "value": "",          "widget": "tab",          "title": "Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "regParamGrid",          "value": "",          "widget": "textfield",          "title": "Regularization Param Grid Search",          "description": "Regularization Parameters for Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "elasticNetGrid",          "value": "",          "widget": "textfield",          "title": "ElasticNet Param Grid Search",          "description": "ElasticNet Parameters for Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "7",      "name": "VectorAssembler",      "description": "Merges multiple columns into a vector column",      "details": "",      "examples": "",      "type": "ml-transformer",      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",      "x": "670.984px",      "y": "270.609px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "inputCols",          "value": "[\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"Age\",\"BMI\",\"DiabetesPedigreeFunction\"]",          "widget": "variables",          "title": "Input Columns",          "description": "Input column of type - all numeric, boolean and vector",          "datatypes": [            "integer",            "long",            "double",            "float",            "vectorudt"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputCol",          "value": "feature_vector",          "widget": "textfield",          "title": "Output Column",          "description": "Output column name",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "8",      "name": "Split",      "description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data. For example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows and the other containing the remaining 30%.",      "details": "",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.ml.NodeSplit",      "x": "844.965px",      "y": "273.609px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "fraction1",          "value": ".8",          "widget": "textfield",          "title": "Fraction 1",          "description": "Fraction to be used for Splitting the DataFrame into two. The first DataFrame would go to the lower edge output. The other would go to the higher edge output.",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "9",      "name": "Predict",      "description": "Predict node takes in a DataFrame and Model and makes predictions",      "details": "",      "examples": "",      "type": "ml-predict",      "nodeClass": "fire.nodes.ml.NodePredict",      "x": "1053.96px",      "y": "396.633px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "10",      "name": "BinaryClassificationEvaluator",      "description": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.",      "details": "Evaluator for binary classification, which expects two input columns: rawPrediction and label.<br>\n<br>\n<br>\nMore at Spark MLlib/ML docs page : <a href=\"http://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#binary-classification</a><br>",      "examples": "",      "type": "ml-evaluator",      "nodeClass": "fire.nodes.ml.NodeBinaryClassificationEvaluator",      "x": "1060.97px",      "y": "555.594px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "labelCol",          "value": "Outcome",          "widget": "variable",          "title": "Label Column",          "description": "The label column for model fitting.",          "datatypes": [            "double"          ],          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "predictionCol",          "value": "prediction",          "widget": "variable",          "title": "Prediction Column",          "description": "The prediction column.",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "metricName",          "value": "areaUnderROC",          "widget": "array",          "title": "Metric Name",          "description": "The metric used in evaluation.",          "optionsArray": [            "areaUnderROC",            "areaUnderPR",            "gini"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    }  ],  "edges": [    {      "source": "1",      "target": "2",      "id": 1    },    {      "source": "2",      "target": "3",      "id": 2    },    {      "source": "3",      "target": "4",      "id": 3    },    {      "source": "4",      "target": "7",      "id": 4    },    {      "source": "8",      "target": "6",      "id": 5    },    {      "source": "6",      "target": "9",      "id": 6    },    {      "source": "8",      "target": "9",      "id": 7    },    {      "source": "9",      "target": "10",      "id": 8    },    {      "source": "9",      "target": "5",      "id": 9    },    {      "source": "7",      "target": "8",      "id": 10    }  ],  "dataSetDetails": [],  "engine": "scala"}
{	"name": "Click-thru Prediction Using GBT",	"uuid": "af9bb76d-df6b-473f-a00e-6f9b2d294a52",	"category": "Prediction",	"description": "Performs Click-thru Predictions",	"parameters": "-",	"nodes": [		{			"id": "1",			"name": "DatasetStructured",			"description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",			"details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",			"examples": "",			"type": "dataset",			"nodeClass": "fire.nodes.dataset.NodeDatasetStructured",			"x": "67.9688px",			"y": "141.953px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dataset",					"value": "7fff0810-eb50-4b7e-8c9a-a55dcc2578f3",					"widget": "dataset",					"title": "Dataset",					"description": "Selected Dataset",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "2",			"name": "ConcatColumns",			"description": "This node creates a new DataFrame by concatenating the specified columns of the input DataFrame",			"details": "It creates a new DataFrame by concatenating specified columns of the input DataFrame into a new column.<br>\n<br>\nA new column is added to the incoming DataFrame by concatenating the specified columns. The new DataFrame is sent to the output of this Node.<br>",			"examples": "If incoming Dataframe has two columns [CUST_CD] and [CUST_NAME] which need to be concatenated to new column [CUST_IDENTIFIER] using separator [-] then output Dataframe would<br>\nbe created as below:<br>\n<br>\n<ul>\n<li> CUST_CD : C001 </li>\n<li> CUST_NAME : DAVID</li>\n<li> CUST_IDENTIFIER : C001-DAVID</li>\n</ul>",			"type": "transform",			"nodeClass": "fire.nodes.etl.NodeConcatColumns",			"x": "69.9375px",			"y": "329.969px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"site_id\",\"app_id\"]",					"widget": "variables",					"title": "Columns",					"description": "Columns to be concatenated",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "site_app_id",					"widget": "textfield",					"title": "Concatenated Column Name",					"description": "Column name for the concatenated columns",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "sep",					"value": "|",					"widget": "textfield",					"title": "Separator",					"description": "Separator to be used when concatenating the columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "3",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "This node is used to print incoming dataset.<br>\n<br>\nNumber of rows that needs to be printed can be configured in the node.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "309.969px",			"y": "330.969px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "3",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "displayDataType",					"value": "true",					"widget": "array",					"title": "Display Data Type",					"description": "If true display rows DataType",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "4",			"name": "StringIndexer",			"description": "StringIndexer encodes a string column of labels to a column of label indices",			"details": "StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0.<br>\nIf the input column is numeric, we cast it to string and index the string values.<br>\n                                                                                                  <br>\nMore at Spark MLlib/ML docs page : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#stringindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#stringindexer</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#stringindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#stringindexer</a></h2>\n<br>\nimport org.apache.spark.ml.feature.StringIndexer<br>\n<br>\nval df = spark.createDataFrame(<br>\n  Seq((0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\"))<br>\n).toDF(\"id\", \"category\")<br>\n<br>\nval indexer = new StringIndexer()<br>\n  .setInputCol(\"category\")<br>\n  .setOutputCol(\"categoryIndex\")<br>\n<br>\nval indexed = indexer.fit(df).transform(df)<br>\nindexed.show()<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeStringIndexer",			"x": "295.953px",			"y": "142.938px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "handleInvalid",					"value": "error",					"widget": "array",					"title": "Handle Invalid",					"description": "Invalid entries to be skipped or thrown error",					"optionsMap": {						"skip": "skip",						"error": "error"					},					"optionsArray": [						"skip",						"error"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"site_app_id\"]",					"widget": "variables_list_select",					"title": "Input Columns",					"description": "Input columns for encoding",					"datatypes": [						"string"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCols",					"value": "[\"site_app_id_index\"]",					"widget": "variables_list_textfield",					"title": "Output Columns",					"description": "Output columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "5",			"name": "OneHotEncoder",			"description": "Maps a column of label indices to a column of binary vectors, with at most a single one-value",			"details": "One-hot encoding maps a column of label indices to a column of binary vectors, with at most a single one-value. <br>\nThis encoding allows algorithms which expect continuous features, such as Logistic Regression, to use categorical features.<br>\n<br>\nMore at Spark MLlib/ML docs page : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#onehotencoder\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#onehotencoder</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#onehotencoder\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#onehotencoder</a></h2>\n<br>\nimport org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer}<br>\n<br>\nval df = spark.createDataFrame(Seq(<br>\n  (0, \"a\"),<br>\n  (1, \"b\"),<br>\n  (2, \"c\"),<br>\n  (3, \"a\"),<br>\n  (4, \"a\"),<br>\n  (5, \"c\")<br>\n)).toDF(\"id\", \"category\")<br>\n<br>\nval indexer = new StringIndexer()<br>\n  .setInputCol(\"category\")<br>\n  .setOutputCol(\"categoryIndex\")<br>\n  .fit(df)<br>\nval indexed = indexer.transform(df)<br>\n<br>\nval encoder = new OneHotEncoder()<br>\n  .setInputCol(\"categoryIndex\")<br>\n  .setOutputCol(\"categoryVec\")<br>\nval encoded = encoder.transform(indexed)<br>\nencoded.select(\"id\", \"categoryVec\").show()<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeOneHotEncoder",			"x": "553.938px",			"y": "142.922px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"site_app_id_index\"]",					"widget": "variables_list_select",					"title": "Input Columns",					"description": "Input columns for encoding",					"datatypes": [						"integer",						"long",						"double",						"float"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCols",					"value": "[\"site_app_id_nohe\"]",					"widget": "variables_list_textfield",					"title": "Output Columns",					"description": "Output columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "7",			"name": "VectorAssembler",			"description": "Merges multiple columns into a vector column",			"details": "VectorAssembler is a transformer that combines a given list of columns into a single vector column. <br>\nIt is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. <br>\nVectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.<br>\n<br>\nMore details are available at:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorAssembler<br>\nimport org.apache.spark.ml.linalg.Vectors<br>\n<br>\nval dataset = spark.createDataFrame(<br>\n  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))<br>\n).toDF(\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\")<br>\n<br>\nval assembler = new VectorAssembler()<br>\n  .setInputCols(Array(\"hour\", \"mobile\", \"userFeatures\"))<br>\n  .setOutputCol(\"features\")<br>\n<br>\nval output = assembler.transform(dataset)<br>\nprintln(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")<br>\noutput.select(\"features\", \"clicked\").show(false)<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeVectorAssembler",			"x": "555.938px",			"y": "324.922px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"hour\",\"C1\",\"banner_pos\",\"device_type\",\"device_conn_type\",\"col16\",\"col17\",\"col18\",\"col19\",\"col20\",\"col21\",\"col22\",\"col23\",\"site_app_id_nohe\"]",					"widget": "variables",					"title": "Input Columns",					"description": "Input column of type - all numeric, boolean and vector",					"datatypes": [						"integer",						"long",						"double",						"float",						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "features",					"widget": "textfield",					"title": "Output Column",					"description": "Output column name",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "handleInvalid",					"value": "error",					"widget": "array",					"title": "HandleInvalid",					"description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",					"optionsArray": [						"error",						"skip",						"keep"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "8",			"name": "VectorIndexer",			"description": "Vector Indexer indexes categorical features inside of a Vector. It decides which features are categorical and converts them to category indices. The decision is based on the number of distinct values of a feature.",			"details": "VectorIndexer helps index categorical features in datasets of Vectors. It can both automatically decide which features are categorical and convert original values to category indices.<br>\nMore details are available at: <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer\" target=\"_blank\">spark.apache.org/docs/2.0.0/ml-features.html#vectorindexer</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorIndexer<br>\n<br>\nval data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\nval indexer = new VectorIndexer()<br>\n  .setInputCol(\"features\")<br>\n  .setOutputCol(\"indexed\")<br>\n  .setMaxCategories(10)<br>\n<br>\nval indexerModel = indexer.fit(data)<br>\n<br>\nval categoricalFeatures: Set[Int] = indexerModel.categoryMaps.keys.toSet<br>\nprintln(s\"Chose ${categoricalFeatures.size} categorical features: \" +<br>\n  categoricalFeatures.mkString(\", \"))<br>\n<br>\n// Create new column \"indexed\" with categorical values transformed to indices<br>\nval indexedData = indexerModel.transform(data)<br>\nindexedData.show()<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeVectorIndexer",			"x": "812.938px",			"y": "322.922px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCol",					"value": "features",					"widget": "variable",					"title": "Input Column",					"description": "The Input column name",					"datatypes": [						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "features_index_vec",					"widget": "textfield",					"title": "Output Column",					"description": "Output column name",					"datatypes": [						"vectorudt"					],					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxCategories",					"value": "10",					"widget": "textfield",					"title": "Maximum Categories",					"description": "Threshold for the number of values a categorical feature can take. If a feature is found to have > maxCategories values, then it is declared continuous. Must be >= 2",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "9",			"name": "Split",			"description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data. For example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).",			"details": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data.<br>\n<br>\nFor example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).<br>\n<br>\nThe split node can be used for splitting the DataFrame for training and test datasets used in Machine Learning.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.ml.NodeSplit",			"x": "804.98px",			"y": "135.957px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "fraction1",					"value": ".8",					"widget": "textfield",					"title": "Fraction 1",					"description": "Fraction to be used for Splitting the DataFrame into two. The first DataFrame would go to the lower edge output. The other would go to the higher edge output.",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "10",			"name": "GBTClassifier",			"description": "Gradient-Boosted Trees (GBTs) is a learning algorithm for classification. It supports binary labels, as well as both continuous and categorical features. Note: Multiclass labels are not currently supported.",			"details": "Gradient-boosted trees (GBTs) are a popular classification and regression method using ensembles of decision trees. <br>\n<br>\nMore details are available at : <a href=\"http://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier</a><br>",			"examples": "Below example is available at :<a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier</a><br>\n<br>\nimport org.apache.spark.ml.Pipeline<br>\nimport org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}<br>\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator<br>\nimport org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}<br>\n<br>\n// Load and parse the data file, converting it to a DataFrame.<br>\nval data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\n// Index labels, adding metadata to the label column.<br>\n// Fit on whole dataset to include all labels in index.<br>\nval labelIndexer = new StringIndexer()<br>\n  .setInputCol(\"label\")<br>\n  .setOutputCol(\"indexedLabel\")<br>\n  .fit(data)<br>\n// Automatically identify categorical features, and index them.<br>\n// Set maxCategories so features with > 4 distinct values are treated as continuous.<br>\nval featureIndexer = new VectorIndexer()<br>\n  .setInputCol(\"features\")<br>\n  .setOutputCol(\"indexedFeatures\")<br>\n  .setMaxCategories(4)<br>\n  .fit(data)<br>\n<br>\n// Split the data into training and test sets (30% held out for testing).<br>\nval Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))<br>\n<br>\n// Train a GBT model.<br>\nval gbt = new GBTClassifier()<br>\n  .setLabelCol(\"indexedLabel\")<br>\n  .setFeaturesCol(\"indexedFeatures\")<br>\n  .setMaxIter(10)<br>\n  .setFeatureSubsetStrategy(\"auto\")<br>\n<br>\n// Convert indexed labels back to original labels.<br>\nval labelConverter = new IndexToString()<br>\n  .setInputCol(\"prediction\")<br>\n  .setOutputCol(\"predictedLabel\")<br>\n  .setLabels(labelIndexer.labelsArray(0))<br>\n<br>\n// Chain indexers and GBT in a Pipeline.<br>\nval pipeline = new Pipeline()<br>\n  .setStages(Array(labelIndexer, featureIndexer, gbt, labelConverter))<br>\n<br>\n// Train model. This also runs the indexers.<br>\nval model = pipeline.fit(trainingData)<br>\n<br>\n// Make predictions.<br>\nval predictions = model.transform(testData)<br>\n<br>\n// Select example rows to display.<br>\npredictions.select(\"predictedLabel\", \"label\", \"features\").show(5)<br>\n<br>\n// Select (prediction, true label) and compute test error.<br>\nval evaluator = new MulticlassClassificationEvaluator()<br>\n  .setLabelCol(\"indexedLabel\")<br>\n  .setPredictionCol(\"prediction\")<br>\n  .setMetricName(\"accuracy\")<br>\nval accuracy = evaluator.evaluate(predictions)<br>\nprintln(s\"Test Error = ${1.0 - accuracy}\")<br>\n<br>\nval gbtModel = model.stages(2).asInstanceOf[GBTClassificationModel]<br>\nprintln(s\"Learned classification GBT model:\\n ${gbtModel.toDebugString}\")<br>",			"type": "ml-estimator",			"nodeClass": "fire.nodes.ml.NodeGBTClassifier",			"x": "1072.95px",			"y": "28.9648px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "featuresCol",					"value": "features_index_vec",					"widget": "variable",					"title": "Features Column",					"description": "Features column of type vectorUDT for model fitting",					"datatypes": [						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "click",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"widget": "textfield",					"title": "Prediction Column",					"description": "The prediction column created during model scoring.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "impurity",					"value": "gini",					"widget": "array",					"title": "Impurity",					"description": "The Criterion used for information gain calculation",					"optionsArray": [						"gini",						"entropy"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "lossType",					"value": "logistic",					"widget": "array",					"title": "Loss Function",					"description": "The Loss function which GBT tries to minimize",					"optionsArray": [						"logistic"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxBins",					"value": "32",					"widget": "textfield",					"title": "Max Bins",					"description": "The maximum number of bins used for discretizing continuous features.Must be >= 2 and >= number of categories in any categorical feature.",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxDepth",					"value": "5",					"widget": "textfield",					"title": "Max Depth",					"description": "The Maximum depth of a tree",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxIter",					"value": "20",					"widget": "textfield",					"title": "Max Iterations",					"description": "The maximum number of iterations(>=0)(a.k.a numtrees)",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "minInfoGain",					"value": "",					"widget": "textfield",					"title": "Min Information Gain",					"description": "The Minimum information gain for a split to be considered at a tree node",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "minInstancesPerNode",					"value": "1",					"widget": "textfield",					"title": "Min Instances Per Node",					"description": "The Minimum number of instances each child must have after split",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "subsamplingRate",					"value": "1.0",					"widget": "textfield",					"title": "Subsampling Rate",					"description": "The fraction of the training data used for learning each decision tree.",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "seed",					"value": "-1",					"widget": "textfield",					"title": "Seed",					"description": "The random seed",					"datatypes": [						"long"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "stepSize",					"value": "0.1",					"widget": "textfield",					"title": "Step Size",					"description": "Step size (a.k.a. learning rate), The step size to be used for each iteration of optimization.",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "cacheNodeIds",					"value": "false",					"widget": "array",					"title": "Cache Node Ids",					"description": "The caching nodes IDs. Can speed up training of deeper trees.",					"datatypes": [						"boolean"					],					"optionsArray": [						"false",						"true"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "checkpointInterval",					"value": "10",					"widget": "textfield",					"title": "Checkpoint Interval",					"description": "The checkpoint interval. E.g. 10 means that the cache will get checkpointed every 10 iterations.Set checkpoint interval (>= 1) or disable checkpoint (-1)",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxMemoryInMB",					"value": "256",					"widget": "textfield",					"title": "Max memory",					"description": "Maximum memory in MB allocated to histogram aggregation.",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "gridSearch",					"value": "",					"widget": "tab",					"title": "Grid Search",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "minInfoGainGrid",					"value": "",					"widget": "textfield",					"title": "Min Information Gain Param Grid Search",					"description": "Min Information Gain Parameters for Grid Search",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxBinsGrid",					"value": "",					"widget": "textfield",					"title": "Max Bins Param Grid Search",					"description": "Max Bins Parameters for Grid Search",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxDepthGrid",					"value": "",					"widget": "textfield",					"title": "Max Depth Param Grid Search",					"description": "Max Depth Parameters for Grid Search",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxIterGrid",					"value": "",					"widget": "textfield",					"title": "Max Iteration Param Grid Search",					"description": "Max Iteration Parameters for Grid Search",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "11",			"name": "Predict",			"description": "Predict node takes in a DataFrame and Model and makes predictions",			"details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",			"examples": "",			"type": "ml-predict",			"nodeClass": "fire.nodes.ml.NodePredict",			"x": "1078.94px",			"y": "222.938px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "12",			"name": "MulticlassClassificationEvaluator",			"description": "Evaluator for multiclass classification, which expects two input columns: score and label.",			"details": "Evaluator for multiclass classification, which expects two input columns: score and label.<br>\n<br>\nMore at Spark MLlib/ML docs page :<a href=\"https://spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification</a><br>",			"examples": "<h2>Below example is available at : <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification</a></h2>\n<br>\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS<br>\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics<br>\nimport org.apache.spark.mllib.regression.LabeledPoint<br>\nimport org.apache.spark.mllib.util.MLUtils<br>\n<br>\n// Load training data in LIBSVM format<br>\nval data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_multiclass_classification_data.txt\")<br>\n<br>\n// Split data into training (60%) and test (40%)<br>\nval Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)<br>\ntraining.cache()<br>\n<br>\n// Run training algorithm to build the model<br>\nval model = new LogisticRegressionWithLBFGS()<br>\n  .setNumClasses(3)<br>\n  .run(training)<br>\n<br>\n// Compute raw scores on the test set<br>\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =><br>\n  val prediction = model.predict(features)<br>\n  (prediction, label)<br>\n}<br>\n<br>\n// Instantiate metrics object<br>\nval metrics = new MulticlassMetrics(predictionAndLabels)<br>\n<br>\n// Confusion matrix<br>\nprintln(\"Confusion matrix:\")<br>\nprintln(metrics.confusionMatrix)<br>\n<br>\n// Overall Statistics<br>\nval accuracy = metrics.accuracy<br>\nprintln(\"Summary Statistics\")<br>\nprintln(s\"Accuracy = $accuracy\")<br>\n<br>\n// Precision by label<br>\nval labels = metrics.labels<br>\nlabels.foreach { l =><br>\n  println(s\"Precision($l) = \" + metrics.precision(l))<br>\n}<br>\n<br>\n// Recall by label<br>\nlabels.foreach { l =><br>\n  println(s\"Recall($l) = \" + metrics.recall(l))<br>\n}<br>\n<br>\n// False positive rate by label<br>\nlabels.foreach { l =><br>\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))<br>\n}<br>\n<br>\n// F-measure by label<br>\nlabels.foreach { l =><br>\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))<br>\n}<br>\n<br>\n// Weighted stats<br>\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")<br>\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")<br>\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")<br>\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")<br>",			"type": "ml-evaluator",			"nodeClass": "fire.nodes.ml.NodeMulticlassClassificationEvaluator",			"x": "1084.95px",			"y": "431.953px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "click",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting.",					"datatypes": [						"double"					],					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"value": "prediction",					"widget": "variable",					"title": "Prediction Column",					"description": "The prediction column.",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "metricName",					"value": "f1",					"widget": "array",					"title": "Metric Name",					"description": "The metric used in evaluation.",					"optionsArray": [						"f1",						"accuracy",						"weightedPrecision",						"weightedRecall"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "14",			"name": "StickyNote",			"description": "Allows capturing Notes on the Workflow",			"details": "",			"examples": "",			"type": "sticky",			"nodeClass": "fire.nodes.doc.NodeStickyNote",			"x": "56px",			"y": "442px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "bgColor",					"value": "blue",					"widget": "textfield",					"title": "Bg Color",					"description": "Background of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "width",					"value": "702px",					"widget": "textfield",					"title": "Width",					"description": "Width of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "height",					"value": "305px",					"widget": "textfield",					"title": "Height",					"description": "Height of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "comment",					"value": "<h1>Click-Thu Rate Prediction</h1><p><br></p><p>https://www.kaggle.com/c/avazu-ctr-prediction</p><p><br></p><h2>Goal</h2><p><br></p><p>Create a model for predicting clicks on banner ads.</p><p><br></p><h2>Solution</h2><p><br></p><p>This workflow uses GBTClassifier. It creates a label column to determine if the click happened. It collects the features using a VectorAssembler.</p>",					"widget": "textarea_rich",					"title": "Comment",					"description": "Comments for the Workflow",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "15",			"name": "StickyNote",			"description": "Allows capturing Notes on the Workflow",			"details": "",			"examples": "",			"type": "sticky",			"nodeClass": "fire.nodes.doc.NodeStickyNote",			"x": "23px",			"y": "23px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "bgColor",					"value": "gray",					"widget": "textfield",					"title": "Bg Color",					"description": "Background of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "width",					"value": "255px",					"widget": "textfield",					"title": "Width",					"description": "Width of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "height",					"value": "73px",					"widget": "textfield",					"title": "Height",					"description": "Height of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "comment",					"value": "<p>Read in the Click thru data</p>",					"widget": "textarea_rich",					"title": "Comment",					"description": "Comments for the Workflow",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		}	],	"edges": [		{			"source": "1",			"target": "2",			"id": 1		},		{			"source": "2",			"target": "3",			"id": 2		},		{			"source": "3",			"target": "4",			"id": 3		},		{			"source": "4",			"target": "5",			"id": 4		},		{			"source": "7",			"target": "8",			"id": 5		},		{			"source": "8",			"target": "9",			"id": 6		},		{			"source": "9",			"target": "10",			"id": 7		},		{			"source": "10",			"target": "11",			"id": 8		},		{			"source": "9",			"target": "11",			"id": 9		},		{			"source": "11",			"target": "12",			"id": 10		},		{			"source": "5",			"target": "7",			"id": 11		}	],	"dataSetDetails": [		{			"id": 621,			"uuid": "7fff0810-eb50-4b7e-8c9a-a55dcc2578f3",			"header": false,			"path": "data/ctr_avazu_dataset/train_sample.csv",			"delimiter": ",",			"datasetType": "CSV",			"datasetSchema": "{\"colNames\":[\"id\",\"click\",\"hour\",\"C1\",\"banner_pos\",\"site_id\",\"site_domain\",\"site_category\",\"app_id\",\"app_domain\",\"app_category\",\"device_id\",\"device_ip\",\"device_model\",\"device_type\",\"device_conn_type\",\"col16\",\"col17\",\"col18\",\"col19\",\"col20\",\"col21\",\"col22\",\"col23\"],\"colTypes\":[\"STRING\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"STRING\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"],\"colFormats\":[],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"TEXT\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\"]}"		}	],	"engine": "scala"}
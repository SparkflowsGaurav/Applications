{	"name": "WineQuality Prediction Using MultilayerPerceptronClassifier",	"uuid": "4d259611-fff5-45f1-895f-4f416be08b4d",	"category": "Prediction",	"nodes": [		{			"id": "1",			"name": "ReadCSV",			"description": "It reads in CSV files and creates a DataFrame from it",			"details": "This node reads CSV files and creates a DataFrame from it.<br>",			"examples": "",			"type": "dataset",			"nodeClass": "fire.nodes.dataset.NodeDatasetCSV",			"x": "35.25px",			"y": "374px",			"hint": "Whenever the file is changed, Refresh the Schema",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "path",					"value": "data/wine-data/winequality.csv",					"widget": "textfield",					"title": "Path",					"description": "Path of the Text file/directory",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "separator",					"value": ";",					"widget": "textfield",					"title": "Separator",					"description": "CSV Separator",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "header",					"value": "true",					"widget": "array",					"title": "Header",					"description": "Does the file have a header row",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dropSpecialCharacterInColumnName",					"value": "true",					"widget": "array",					"title": "Drop Special Character In ColumnName",					"description": "Drop the SpecialCharacter and Space in Column Name.",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dropMalformed",					"value": "true",					"widget": "array",					"title": "Drop Malformed",					"description": "Whether to drop Malformed records or error",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"fixed_acidity\",\"volatile_acidity\",\"citric_acid\",\"residual_sugar\",\"chlorides\",\"free_sulfur_dioxide\",\"total_sulfur_dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]",					"widget": "schema_col_names",					"title": "Column Names for the CSV",					"description": "New Output Columns of the SQL",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",					"widget": "schema_col_types",					"title": "Column Types for the CSV",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Column Formats for the CSV",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "3",			"name": "VectorAssembler",			"description": "Merges multiple columns into a vector column",			"details": "VectorAssembler is a transformer that combines a given list of columns into a single vector column. <br>\nIt is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. <br>\nVectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.<br>\n<br>\nMore details are available at:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a><br>",			"examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorAssembler<br>\nimport org.apache.spark.ml.linalg.Vectors<br>\n<br>\nval dataset = spark.createDataFrame(<br>\n  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))<br>\n).toDF(\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\")<br>\n<br>\nval assembler = new VectorAssembler()<br>\n  .setInputCols(Array(\"hour\", \"mobile\", \"userFeatures\"))<br>\n  .setOutputCol(\"features\")<br>\n<br>\nval output = assembler.transform(dataset)<br>\nprintln(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")<br>\noutput.select(\"features\", \"clicked\").show(false)<br>",			"type": "ml-transformer",			"nodeClass": "fire.nodes.ml.NodeVectorAssembler",			"x": "376.25px",			"y": "384px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "inputCols",					"value": "[\"fixed_acidity\",\"volatile_acidity\",\"citric_acid\",\"residual_sugar\",\"chlorides\",\"free_sulfur_dioxide\",\"total_sulfur_dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"]",					"widget": "variables",					"title": "Input Columns",					"description": "Input column of type - all numeric, boolean and vector",					"datatypes": [						"integer",						"long",						"double",						"float",						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputCol",					"value": "feature_v",					"widget": "textfield",					"title": "Output Column",					"description": "Output column name",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "handleInvalid",					"value": "error",					"widget": "array",					"title": "HandleInvalid",					"description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",					"optionsArray": [						"error",						"skip",						"keep"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "5",			"name": "Split",			"description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data. For example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).",			"details": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data.<br>\n<br>\nFor example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).<br>\n<br>\nThe split node can be used for splitting the DataFrame for training and test datasets used in Machine Learning.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.ml.NodeSplit",			"x": "554.25px",			"y": "379px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "fraction1",					"value": ".6",					"widget": "textfield",					"title": "Fraction 1",					"description": "Fraction to be used for Splitting the DataFrame into two. The first DataFrame would go to the lower edge output. The other would go to the higher edge output.",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "6",			"name": "MultiLayerPerceptron",			"description": "It supports creation of full connected neural network.",			"details": "Multilayer perceptron classifier (MLPC) is a classifier based on the feedforward artificial neural network. <br>\nMLPC consists of multiple layers of nodes. Each layer is fully connected to the next layer in the network. Nodes in the input layer represent the input data.<br>",			"examples": "Below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#multilayer-perceptron-classifier</a><br>\n<br>\nimport org.apache.spark.ml.classification.MultilayerPerceptronClassifier<br>\nimport org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator<br>\n<br>\n// Load the data stored in LIBSVM format as a DataFrame.<br>\nval data = spark.read.format(\"libsvm\")<br>\n  .load(\"data/mllib/sample_multiclass_classification_data.txt\")<br>\n<br>\n// Split the data into train and test<br>\nval splits = data.randomSplit(Array(0.6, 0.4), seed = 1234L)<br>\nval train = splits(0)<br>\nval test = splits(1)<br>\n<br>\n// specify layers for the neural network:<br>\n// input layer of size 4 (features), two intermediate of size 5 and 4<br>\n// and output of size 3 (classes)<br>\nval layers = Array[Int](4, 5, 4, 3)<br>\n<br>\n// create the trainer and set its parameters<br>\nval trainer = new MultilayerPerceptronClassifier()<br>\n  .setLayers(layers)<br>\n  .setBlockSize(128)<br>\n  .setSeed(1234L)<br>\n  .setMaxIter(100)<br>\n<br>\n// train the model<br>\nval model = trainer.fit(train)<br>\n<br>\n// compute accuracy on the test set<br>\nval result = model.transform(test)<br>\nval predictionAndLabels = result.select(\"prediction\", \"label\")<br>\nval evaluator = new MulticlassClassificationEvaluator()<br>\n  .setMetricName(\"accuracy\")<br>\n<br>\nprintln(s\"Test set accuracy = ${evaluator.evaluate(predictionAndLabels)}\")<br>",			"type": "ml-estimator",			"nodeClass": "fire.nodes.ml.NodeMultilayerPerceptron",			"x": "762.25px",			"y": "379px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "featuresCol",					"value": "feature_v",					"widget": "variable",					"title": "Features Column",					"description": "Features column of type vectorUDT for model fitting",					"datatypes": [						"vectorudt"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "quality_lable",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"value": "",					"widget": "textfield",					"title": "Prediction Column",					"description": "The prediction column created during model scoring.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "layers",					"value": "11, 5, 4, 3",					"widget": "textfield",					"title": "Layers - comma separated list of integers",					"description": "The integer array specifying the number of activation units in each layer",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "maxIter",					"value": "100",					"widget": "textfield",					"title": "Max number of iterations",					"description": "Number of iterations to train the Neural network",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "blockSize",					"value": "128",					"widget": "textfield",					"title": "Block Size",					"description": "Block size",					"datatypes": [						"integer"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "seed",					"value": "1234",					"widget": "textfield",					"title": "Seed",					"description": "The initial seed to initialise the neural network.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "tol",					"value": "1e-6",					"widget": "textfield",					"title": "Tol",					"description": "",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "solver",					"value": "l-bfgs",					"widget": "textfield",					"title": "Solver",					"description": "solver",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "stepSize",					"value": "0.03",					"widget": "textfield",					"title": "Step Size",					"description": "Step size",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "7",			"name": "Predict",			"description": "Predict node takes in a DataFrame and Model and makes predictions",			"details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",			"examples": "",			"type": "ml-predict",			"nodeClass": "fire.nodes.ml.NodePredict",			"x": "690.25px",			"y": "561px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "8",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "This node is used to print incoming dataset.<br>\n<br>\nNumber of rows that needs to be printed can be configured in the node.<br>",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "697.25px",			"y": "729px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "10",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "displayDataType",					"value": "true",					"widget": "array",					"title": "Display Data Type",					"description": "If true display rows DataType",					"optionsArray": [						"true",						"false"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		},		{			"id": "9",			"name": "MulticlassClassificationEvaluator",			"description": "Evaluator for multiclass classification, which expects two input columns: score and label.",			"details": "Evaluator for multiclass classification, which expects two input columns: score and label.<br>\n<br>\nMore at Spark MLlib/ML docs page :<a href=\"https://spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/1.6.0/mllib-evaluation-metrics.html#multiclass-classification</a><br>",			"examples": "<h2>Below example is available at : <a href=\"https://spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification\" target=\"_blank\">spark.apache.org/docs/latest/mllib-evaluation-metrics.html#multiclass-classification</a></h2>\n<br>\nimport org.apache.spark.mllib.classification.LogisticRegressionWithLBFGS<br>\nimport org.apache.spark.mllib.evaluation.MulticlassMetrics<br>\nimport org.apache.spark.mllib.regression.LabeledPoint<br>\nimport org.apache.spark.mllib.util.MLUtils<br>\n<br>\n// Load training data in LIBSVM format<br>\nval data = MLUtils.loadLibSVMFile(sc, \"data/mllib/sample_multiclass_classification_data.txt\")<br>\n<br>\n// Split data into training (60%) and test (40%)<br>\nval Array(training, test) = data.randomSplit(Array(0.6, 0.4), seed = 11L)<br>\ntraining.cache()<br>\n<br>\n// Run training algorithm to build the model<br>\nval model = new LogisticRegressionWithLBFGS()<br>\n  .setNumClasses(3)<br>\n  .run(training)<br>\n<br>\n// Compute raw scores on the test set<br>\nval predictionAndLabels = test.map { case LabeledPoint(label, features) =><br>\n  val prediction = model.predict(features)<br>\n  (prediction, label)<br>\n}<br>\n<br>\n// Instantiate metrics object<br>\nval metrics = new MulticlassMetrics(predictionAndLabels)<br>\n<br>\n// Confusion matrix<br>\nprintln(\"Confusion matrix:\")<br>\nprintln(metrics.confusionMatrix)<br>\n<br>\n// Overall Statistics<br>\nval accuracy = metrics.accuracy<br>\nprintln(\"Summary Statistics\")<br>\nprintln(s\"Accuracy = $accuracy\")<br>\n<br>\n// Precision by label<br>\nval labels = metrics.labels<br>\nlabels.foreach { l =><br>\n  println(s\"Precision($l) = \" + metrics.precision(l))<br>\n}<br>\n<br>\n// Recall by label<br>\nlabels.foreach { l =><br>\n  println(s\"Recall($l) = \" + metrics.recall(l))<br>\n}<br>\n<br>\n// False positive rate by label<br>\nlabels.foreach { l =><br>\n  println(s\"FPR($l) = \" + metrics.falsePositiveRate(l))<br>\n}<br>\n<br>\n// F-measure by label<br>\nlabels.foreach { l =><br>\n  println(s\"F1-Score($l) = \" + metrics.fMeasure(l))<br>\n}<br>\n<br>\n// Weighted stats<br>\nprintln(s\"Weighted precision: ${metrics.weightedPrecision}\")<br>\nprintln(s\"Weighted recall: ${metrics.weightedRecall}\")<br>\nprintln(s\"Weighted F1 score: ${metrics.weightedFMeasure}\")<br>\nprintln(s\"Weighted false positive rate: ${metrics.weightedFalsePositiveRate}\")<br>",			"type": "ml-evaluator",			"nodeClass": "fire.nodes.ml.NodeMulticlassClassificationEvaluator",			"x": "413.25px",			"y": "570px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "labelCol",					"value": "quality_lable",					"widget": "variable",					"title": "Label Column",					"description": "The label column for model fitting.",					"datatypes": [						"double"					],					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "predictionCol",					"value": "prediction",					"widget": "variable",					"title": "Prediction Column",					"description": "The prediction column.",					"datatypes": [						"double"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "metricName",					"value": "accuracy",					"widget": "array",					"title": "Metric Name",					"description": "The metric used in evaluation.",					"optionsArray": [						"f1",						"accuracy",						"weightedPrecision",						"weightedRecall"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "10",			"name": "StickyNote",			"description": "Allows capturing Notes on the Workflow",			"details": "",			"examples": "",			"type": "sticky",			"nodeClass": "fire.nodes.doc.NodeStickyNote",			"x": "11px",			"y": "11px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "bgColor",					"value": "blue",					"widget": "textfield",					"title": "Bg Color",					"description": "Background of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "width",					"value": "962px",					"widget": "textfield",					"title": "Width",					"description": "Width of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "height",					"value": "317px",					"widget": "textfield",					"title": "Height",					"description": "Height of note",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "comment",					"value": "<p>A feedforward neural network is an artificial neural network wherein connections between the units do not form a cycle. As such, it is different from recurrent neural networks.</p><p>The feedforward neural network was the first and simplest type of artificial neural network devised. In this network, the information moves in only one direction, forward, from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network.</p><p><br></p><p><span style=\"color: rgb(29, 31, 34);\">Multilayer perceptron classifier (MLPC) is a classifier based on the&nbsp;</span><a href=\"https://en.wikipedia.org/wiki/Feedforward_neural_network\" rel=\"noopener noreferrer\" target=\"_blank\" style=\"color: rgb(0, 136, 204); background-color: rgb(255, 255, 255);\">feedforward artificial neural network</a><span style=\"color: rgb(29, 31, 34);\">. MLPC consists of multiple layers of nodes. Each layer is fully connected to the next layer in the network. Nodes in the input layer represent the input data.</span></p><p><br></p><p>The number of nodes&nbsp;<code style=\"color: inherit;\">N </code> in the output layer corresponds to the number of classes.</p><p>MLPC employs backpropagation for learning the model. We use the logistic loss function for optimization and L-BFGS as an optimization routine.</p><p><br></p><p><strong>Specify layers for the neural network:</strong></p><p>&nbsp;Input layer of size 11 (features), two intermediate of size 5 and 4 and output of size 3 (classes).</p>",					"widget": "textarea_rich",					"title": "Comment",					"description": "Comments for the Workflow",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "scala"		},		{			"id": "11",			"name": "SQL",			"description": "This node runs the given SQL on the incoming DataFrame",			"details": "This node receives an input data frame, creates a temporary table on top of that data frame.<br>\nAllows the user to write a SQL which would be executed on the temporary table.<br>\nThe resulting data frame of running the SQL is passed on to the next node.<br>",			"examples": "<h2>SQL Examples</h2>\n<br>\nBelow are some example of SQL. <br>\n<br>\nThey use the Temp Table Name to be : tempTable<br>\n<br>\nThe schem of the Input Dataframe is : id, price, lotsize, bedrooms, bathrms, stories, driveway, recroom, fullbase, gashw, airco, garagepl, prefarea<br>\n<br>\n<h4> avg price of house</h4>\n<br>\nselect avg(price) as avg_price from tempTable<br>\n<br>\n<br>\n<h4> bedrooms with avg price greater than 10000</h4>\n<br>\nselect bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000<br>\n<br>\n<br>\n<h4> house details with bedrooms avg price greater than 10000</h4>\n<br>\nselect tempTable.* , inner_table.avg_price from<br>\n(select bedrooms, avg_price from<br>\n(select bedrooms, avg(price) as avg_price from tempTable group by bedrooms) as temp where avg_price > 10000) as inner_table<br>\nJOIN tempTable ON(inner_table.bedrooms = tempTable.bedrooms)<br>",			"type": "transform",			"nodeClass": "fire.nodes.etl.NodeSQL",			"x": "210.25px",			"y": "376px",			"hint": "Whenever the table is changed, go to Schema tab and Refresh the Schema",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "tempTable",					"value": "fire_temp_table",					"widget": "textfield",					"title": "Temp Table",					"description": "Temp Table Name to be used",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "sql",					"value": "select fixed_acidity, volatile_acidity,\tcitric_acid,\tresidual_sugar,\tchlorides,free_sulfur_dioxide,\ttotal_sulfur_dioxide,\t\n       density,\tpH,\tsulphates,\talcohol,\n       CASE WHEN (quality >= 0 and quality <=4) THEN 0.0\n            WHEN (quality > 4 and quality <= 6) THEN 1.0\n            ELSE 2.0 END AS  quality_lable from fire_temp_table\n                    ",					"widget": "textarea_large",					"type": "sql",					"title": "SQL",					"description": "SQL to be run",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "schema",					"value": "",					"widget": "tab",					"title": "Schema",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"fixed_acidity\",\"volatile_acidity\",\"citric_acid\",\"residual_sugar\",\"chlorides\",\"free_sulfur_dioxide\",\"total_sulfur_dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality_lable\"]",					"widget": "schema_col_names",					"title": "Output Column Names",					"description": "Name of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"]",					"widget": "schema_col_types",					"title": "Output Column Types",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Output Column Formats",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			],			"engine": "all"		}	],	"edges": [		{			"source": "3",			"target": "5",			"id": 1		},		{			"source": "5",			"target": "6",			"id": 2		},		{			"source": "6",			"target": "7",			"id": 3		},		{			"source": "5",			"target": "7",			"id": 4		},		{			"source": "7",			"target": "8",			"id": 5		},		{			"source": "7",			"target": "9",			"id": 6		},		{			"source": "1",			"target": "11",			"id": 7		},		{			"source": "11",			"target": "3",			"id": 8		}	],	"dataSetDetails": [],	"engine": "scala"}
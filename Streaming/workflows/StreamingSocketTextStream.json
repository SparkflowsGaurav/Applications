{"name":"Streaming Socket TextStream","uuid":"a34f9323-d9a7-42a7-a060-2d1f838547ac","category":"Sockets","description":"Stream Processing reading from a Socket","nodes":[{"id":"1","name":"StreamingSocketTextStream","description":"Reads in streaming text from a socket","details":"This Processor reads in messages from a Socketh1:Key FieldsBelow are the key fields of this Processor.*hostname: this is the name of the host from where to read in the messages*port: this is the port number from where to read in the messages","examples":"This Processor reads in messages from a Socketh1:Key FieldsBelow are the key fields of this Processor.*hostname: this is the name of the host from where to read in the messages*port: this is the port number from where to read in the messages","type":"sparkstreaming","nodeClass":"fire.nodes.streaming.NodeStreamingSocketTextStream","x":"124.726px","y":"195.816px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"batchDuration","value":"30","widget":"textfield","title":"Batch Duration in Seconds","description":"Batch Duration in Seconds","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"hostname","value":"localhost","widget":"textfield","title":"Hostname","description":"Host to connect to for listening","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"port","value":"9999","widget":"textfield","title":"Port","description":"Port to connect to ","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"2","name":"PrintNRows","description":"Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output","details":"","examples":"","type":"transform","nodeClass":"fire.nodes.util.NodePrintFirstNRows","x":"463.74px","y":"208.816px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"title","value":"Row Values","widget":"textfield","title":"Title","required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"n","value":"10","widget":"textfield","title":"Num Rows to Print","description":"number of rows to be printed","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"},{"id":"3","name":"Notes","description":"Allows capturing Notes on the Workflow","details":"","examples":"","type":"doc","nodeClass":"fire.nodes.doc.NodeDocLarge","x":"120.979px","y":"15.7604px","fields":[{"name":"storageLevel","value":"DEFAULT","widget":"array","title":"Output Storage Level","description":"Storage Level of the Output Datasets of this Node","optionsArray":["DEFAULT","NONE","DISK_ONLY","DISK_ONLY_2","MEMORY_ONLY","MEMORY_ONLY_2","MEMORY_ONLY_SER","MEMORY_ONLY_SER_2","MEMORY_AND_DISK","MEMORY_AND_DISK_2","MEMORY_AND_DISK_SER","MEMORY_AND_DISK_SER_2","OFF_HEAP"],"required":false,"display":true,"editable":true,"disableRefresh":false},{"name":"comment","value":"\u003ch1\u003eAnalyzing Streaming Workflow using socket Data\u003c/h1\u003e\u003cp\u003e\u003cbr\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eThis workflow reads in streaming text data from a socket every 30 seconds.\u003c/li\u003e\u003cli\u003eHost : localhost Port : 9999\u003c/li\u003e\u003cli\u003eIt then prints out the first 10 rows of the incoming data every 30 seconds.\u003c/li\u003e\u003cli\u003eYou will first need to run Netcat (a small utility found in most Unix-like systems) as a data server by using: nc -lk 9999\u003c/li\u003e\u003cli\u003eMore details are available at : https://spark.apache.org/docs/1.6.0/streaming-programming-guide.html\u003c/li\u003e\u003cli\u003eSparkflows also comes with streamfile.py under the scripts directory. streamfile.py reads in the given input text file, and outputs one line at a time and then sleeps for 1 second.\u003c/li\u003e\u003cli\u003eYou can stream a file (eg: testfile.txt) into netcat with the below command: python streamfile.py testfile.txt| nc -lk 9999\u003c/li\u003e\u003c/ul\u003e","widget":"textarea_rich","title":"Comment","description":"Comments for the Workflow","required":false,"display":true,"editable":true,"disableRefresh":false}],"engine":"scala"}],"edges":[{"source":"1","target":"2","id":1}],"dataSetDetails":[],"engine":"scala"}
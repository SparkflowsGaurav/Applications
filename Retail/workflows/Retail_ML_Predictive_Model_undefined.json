{  "name": "Retail_ML_Predictive_Model",  "uuid": "54228ff3-7592-4a63-b359-49af6220ac30",  "category": "-",  "nodes": [    {      "id": "1",      "name": "Walmart train dataset",      "description": "It reads in CSV files and creates a DataFrame from it",      "details": "This node reads CSV files and creates a DataFrame from it.<br>",      "examples": "",      "type": "dataset",      "nodeClass": "fire.nodes.dataset.NodeDatasetCSV",      "x": "29.9844px",      "y": "75.9766px",      "hint": "Whenever the file is changed, Refresh the Schema",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "path",          "value": "/home/sparkflows/fire-data/Walmart_input_dataset/Retail_Dataset.csv",          "widget": "textfield",          "title": "Path",          "description": "Path of the Text file/directory",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "separator",          "value": ",",          "widget": "textfield",          "title": "Separator",          "description": "CSV Separator",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "header",          "value": "true",          "widget": "array",          "title": "Header",          "description": "Does the file have a header row",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropSpecialCharacterInColumnName",          "value": "false",          "widget": "array",          "title": "Drop Special Character In ColumnName",          "description": "Drop the SpecialCharacter and Space in Column Name.",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropMalformed",          "value": "false",          "widget": "array",          "title": "Drop Malformed",          "description": "Whether to drop Malformed records or error",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColNames",          "value": "[\"_c0\",\"Store\",\"Temperature\",\"Fuel_Price\",\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\"CPI\",\"Unemployment\",\"IsHoliday\",\"Weekly_Sales\",\"Type_A\",\"Type_B\",\"Type_C\",\"Month_1\",\"Month_2\",\"Month_3\",\"Month_4\",\"Month_5\",\"Month_6\",\"Month_7\",\"Month_8\",\"Month_9\",\"Month_10\",\"Month_11\",\"Month_12\",\"Year_2010\",\"Year_2011\",\"Year_2012\",\"Year_2013\",\"WeekofYear_1\",\"WeekofYear_2\",\"WeekofYear_3\",\"WeekofYear_4\",\"WeekofYear_5\",\"WeekofYear_6\",\"WeekofYear_7\",\"WeekofYear_8\",\"WeekofYear_9\",\"WeekofYear_10\",\"WeekofYear_11\",\"WeekofYear_12\",\"WeekofYear_13\",\"WeekofYear_14\",\"WeekofYear_15\",\"WeekofYear_16\",\"WeekofYear_17\",\"WeekofYear_18\",\"WeekofYear_19\",\"WeekofYear_20\",\"WeekofYear_21\",\"WeekofYear_22\",\"WeekofYear_23\",\"WeekofYear_24\",\"WeekofYear_25\",\"WeekofYear_26\",\"WeekofYear_27\",\"WeekofYear_28\",\"WeekofYear_29\",\"WeekofYear_30\",\"WeekofYear_31\",\"WeekofYear_32\",\"WeekofYear_33\",\"WeekofYear_34\",\"WeekofYear_35\",\"WeekofYear_36\",\"WeekofYear_37\",\"WeekofYear_38\",\"WeekofYear_39\",\"WeekofYear_40\",\"WeekofYear_41\",\"WeekofYear_42\",\"WeekofYear_43\",\"WeekofYear_44\",\"WeekofYear_45\",\"WeekofYear_46\",\"WeekofYear_47\",\"WeekofYear_48\",\"WeekofYear_49\",\"WeekofYear_50\",\"WeekofYear_51\",\"WeekofYear_52\"]",          "widget": "schema_col_names",          "title": "Column Names for the CSV",          "description": "New Output Columns of the SQL",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColTypes",          "value": "[\"INTEGER\",\"INTEGER\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"INTEGER\",\"DOUBLE\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\",\"INTEGER\"]",          "widget": "schema_col_types",          "title": "Column Types for the CSV",          "description": "Data Type of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColFormats",          "value": "[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]",          "widget": "schema_col_formats",          "title": "Column Formats for the CSV",          "description": "Format of the Output Columns",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "2",      "name": "Drop Columns",      "description": "This node creates a new DataFrame by dropping the specified columns",      "details": "This node creates a new DataFrame by deleting columns specified as an input.<br>\n<br>\nThe specified columns are dropped from the incoming DataFrame to generate the output DataFrame.<br>",      "examples": "If incoming Dataframe has following columns<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\nand [DOB] and [ADDRESS] need to be dropped from outgoing Dataframe then add following to the Drop list in the Drop Column node:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeDropColumns",      "x": "36.9766px",      "y": "213.977px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropCols",          "value": "[\"_c0\"]",          "widget": "variables",          "title": "Columns",          "description": "The columns to be excluded from the output DataFrame",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "3",      "name": "Cast To Single Type",      "description": "This node creates a new DataFrame by casting the specified input columns to a new data type",      "details": "This node creates a new DataFrame by casting the specified input columns to a new data type. All the selected columns would be cast to the specified data type.<br>\n<br>\nThe boolean field Replace Existing Columns indicates whether the existing column should be replaced or a new column should be created.<br>",      "examples": "If incoming Dataframe has following columns with below specified datatype:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : Datetime</li>\n<li> AGE : Integer</li>\n</ul>\nand [DOB] and [AGE] are selected for casting to [STRING] datatype then outgoing Dataframe would have below datatypes:<br>\n<br>\n<ul>\n<li> CUST_ID : Integer</li>\n<li> CUST_NAME : String</li>\n<li> DOB : String</li>\n<li> AGE : String</li>\n</ul>",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeCastColumnType",      "x": "198.977px",      "y": "211.977px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "inputCols",          "value": "[\"Store\",\"Temperature\",\"Fuel_Price\",\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\"CPI\",\"Unemployment\",\"IsHoliday\",\"Type_A\",\"Type_B\",\"Type_C\",\"Month_1\",\"Month_2\",\"Month_3\",\"Month_4\",\"Month_5\",\"Month_6\",\"Month_7\",\"Month_8\",\"Month_9\",\"Month_10\",\"Month_11\",\"Month_12\",\"Year_2010\",\"Year_2011\",\"Year_2012\",\"Year_2013\",\"WeekofYear_1\",\"WeekofYear_2\",\"WeekofYear_3\",\"WeekofYear_4\",\"WeekofYear_5\",\"WeekofYear_6\",\"WeekofYear_7\",\"WeekofYear_8\",\"WeekofYear_9\",\"WeekofYear_10\",\"WeekofYear_11\",\"WeekofYear_12\",\"WeekofYear_13\",\"WeekofYear_14\",\"WeekofYear_15\",\"WeekofYear_16\",\"WeekofYear_17\",\"WeekofYear_18\",\"WeekofYear_19\",\"WeekofYear_20\",\"WeekofYear_21\",\"WeekofYear_22\",\"WeekofYear_23\",\"WeekofYear_24\",\"WeekofYear_25\",\"WeekofYear_26\",\"WeekofYear_27\",\"WeekofYear_28\",\"WeekofYear_29\",\"WeekofYear_30\",\"WeekofYear_31\",\"WeekofYear_32\",\"WeekofYear_33\",\"WeekofYear_34\",\"WeekofYear_35\",\"WeekofYear_36\",\"WeekofYear_37\",\"WeekofYear_38\",\"WeekofYear_39\",\"WeekofYear_40\",\"WeekofYear_41\",\"WeekofYear_42\",\"WeekofYear_43\",\"WeekofYear_44\",\"WeekofYear_45\",\"WeekofYear_46\",\"WeekofYear_47\",\"WeekofYear_48\",\"WeekofYear_49\",\"WeekofYear_50\",\"WeekofYear_51\",\"WeekofYear_52\"]",          "widget": "variables",          "title": "Columns",          "description": "Columns to be cast to new data type",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputColType",          "value": "DOUBLE",          "widget": "array",          "title": "New Data Type",          "description": "New data type for the selected columns (INTEGER, DOUBLE, STRING, LONG, SHORT)",          "optionsArray": [            "BOOLEAN",            "BYTE",            "DATE",            "DECIMAL",            "DOUBLE",            "FLOAT",            "INTEGER",            "LONG",            "SHORT",            "STRING",            "TIMESTAMP"          ],          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "replaceExistingCols",          "value": "true",          "widget": "array",          "title": "Replace Existing Cols?",          "description": "Whether to replace existing columns or create new ones?",          "optionsArray": [            "true",            "false"          ],          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "4",      "name": "Vector Assembler",      "description": "Merges multiple columns into a vector column",      "details": "VectorAssembler is a transformer that combines a given list of columns into a single vector column. <br>\nIt is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. <br>\nVectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.<br>\n<br>\nMore details are available at:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a><br>",      "examples": "<h2>The below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-features.html#vectorassembler\" target=\"_blank\">spark.apache.org/docs/latest/ml-features.html#vectorassembler</a></h2>\n<br>\nimport org.apache.spark.ml.feature.VectorAssembler<br>\nimport org.apache.spark.ml.linalg.Vectors<br>\n<br>\nval dataset = spark.createDataFrame(<br>\n  Seq((0, 18, 1.0, Vectors.dense(0.0, 10.0, 0.5), 1.0))<br>\n).toDF(\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\")<br>\n<br>\nval assembler = new VectorAssembler()<br>\n  .setInputCols(Array(\"hour\", \"mobile\", \"userFeatures\"))<br>\n  .setOutputCol(\"features\")<br>\n<br>\nval output = assembler.transform(dataset)<br>\nprintln(\"Assembled columns 'hour', 'mobile', 'userFeatures' to vector column 'features'\")<br>\noutput.select(\"features\", \"clicked\").show(false)<br>",      "type": "ml-transformer",      "nodeClass": "fire.nodes.ml.NodeVectorAssembler",      "x": "381.969px",      "y": "74.9766px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "inputCols",          "value": "[\"Store\",\"Temperature\",\"Fuel_Price\",\"MarkDown1\",\"MarkDown2\",\"MarkDown3\",\"MarkDown4\",\"MarkDown5\",\"CPI\",\"Unemployment\",\"IsHoliday\",\"Type_A\",\"Type_B\",\"Type_C\",\"Month_1\",\"Month_2\",\"Month_3\",\"Month_4\",\"Month_5\",\"Month_6\",\"Month_7\",\"Month_8\",\"Month_9\",\"Month_10\",\"Month_11\",\"Month_12\",\"Year_2010\",\"Year_2011\",\"Year_2012\",\"Year_2013\",\"WeekofYear_1\",\"WeekofYear_2\",\"WeekofYear_3\",\"WeekofYear_4\",\"WeekofYear_5\",\"WeekofYear_6\",\"WeekofYear_7\",\"WeekofYear_8\",\"WeekofYear_9\",\"WeekofYear_10\",\"WeekofYear_11\",\"WeekofYear_12\",\"WeekofYear_13\",\"WeekofYear_14\",\"WeekofYear_15\",\"WeekofYear_16\",\"WeekofYear_17\",\"WeekofYear_18\",\"WeekofYear_19\",\"WeekofYear_20\",\"WeekofYear_21\",\"WeekofYear_22\",\"WeekofYear_23\",\"WeekofYear_24\",\"WeekofYear_25\",\"WeekofYear_26\",\"WeekofYear_27\",\"WeekofYear_28\",\"WeekofYear_29\",\"WeekofYear_30\",\"WeekofYear_31\",\"WeekofYear_32\",\"WeekofYear_33\",\"WeekofYear_34\",\"WeekofYear_35\",\"WeekofYear_36\",\"WeekofYear_37\",\"WeekofYear_38\",\"WeekofYear_39\",\"WeekofYear_40\",\"WeekofYear_41\",\"WeekofYear_42\",\"WeekofYear_43\",\"WeekofYear_44\",\"WeekofYear_45\",\"WeekofYear_46\",\"WeekofYear_47\",\"WeekofYear_48\",\"WeekofYear_49\",\"WeekofYear_50\",\"WeekofYear_51\",\"WeekofYear_52\"]",          "widget": "variables",          "title": "Input Columns",          "description": "Input column of type - all numeric, boolean and vector",          "datatypes": [            "integer",            "long",            "double",            "float",            "vectorudt"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "outputCol",          "value": "vectoruid",          "widget": "textfield",          "title": "Output Column",          "description": "Output column name",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "handleInvalid",          "value": "error",          "widget": "array",          "title": "HandleInvalid",          "description": "How to handle invalid data (NULL values). Options are 'skip' (filter out rows with invalid data), 'error' (throw an error), or 'keep' (return relevant number of NaN in the output).",          "optionsArray": [            "error",            "skip",            "keep"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "5",      "name": "Split",      "description": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data. For example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).",      "details": "This node splits the incoming DataFrame into 2. It takes in the fraction to use in splitting the data.<br>\n<br>\nFor example, if the fraction is .7, it would split the data into 2 DataFrames, one containing 70% of the rows(passed from lower edge id to next node) and the other containing the remaining 30%(passed from higher edge id to next node).<br>\n<br>\nThe split node can be used for splitting the DataFrame for training and test datasets used in Machine Learning.<br>",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.ml.NodeSplit",      "x": "385.969px",      "y": "217.977px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "fraction1",          "value": ".8",          "widget": "textfield",          "title": "Fraction 1",          "description": "Fraction to be used for Splitting the DataFrame into two. The first DataFrame would go to the lower edge output. The other would go to the higher edge output.",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "7",      "name": "Spark Predict",      "description": "Predict node takes in a DataFrame and Model and makes predictions",      "details": "Predict node takes in a DataFrame and Model and makes predictions on the data using the Model.<br>",      "examples": "",      "type": "ml-predict",      "nodeClass": "fire.nodes.ml.NodePredict",      "x": "673px",      "y": "354.977px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "9",      "name": "Print N Rows",      "description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",      "details": "This node is used to print incoming dataset.<br>\n<br>\nNumber of rows that needs to be printed can be configured in the node.<br>",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.util.NodePrintFirstNRows",      "x": "900px",      "y": "493px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "title",          "value": "Row Values",          "widget": "textfield",          "title": "Title",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "n",          "value": "100",          "widget": "textfield",          "title": "Num Rows to Print",          "description": "number of rows to be printed",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "displayDataType",          "value": "true",          "widget": "array",          "title": "Display Data Type",          "description": "If true display rows DataType",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "10",      "name": "Random Forest Regression",      "description": "It supports both continuous and categorical features.",      "details": "Random forests are a popular family of classification and regression methods.<br>\nThe DataFrame API supports two major tree ensemble algorithms: Random Forests and Gradient-Boosted Trees (GBTs). Both use spark.ml decision trees as their base models.<br>\n<br>\nMore details are available at Apache Spark ML docs page :<br>\n<br>\n<a href=\"http://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression</a><br>",      "examples": "Below example is available at : <a href=\"https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression\" target=\"_blank\">spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-regression</a><br>\n<br>\nimport org.apache.spark.ml.Pipeline<br>\nimport org.apache.spark.ml.evaluation.RegressionEvaluator<br>\nimport org.apache.spark.ml.feature.VectorIndexer<br>\nimport org.apache.spark.ml.regression.{RandomForestRegressionModel, RandomForestRegressor}<br>\n<br>\n// Load and parse the data file, converting it to a DataFrame.<br>\nval data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")<br>\n<br>\n// Automatically identify categorical features, and index them.<br>\n// Set maxCategories so features with > 4 distinct values are treated as continuous.<br>\nval featureIndexer = new VectorIndexer()<br>\n  .setInputCol(\"features\")<br>\n  .setOutputCol(\"indexedFeatures\")<br>\n  .setMaxCategories(4)<br>\n  .fit(data)<br>\n<br>\n// Split the data into training and test sets (30% held out for testing).<br>\nval Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))<br>\n<br>\n// Train a RandomForest model.<br>\nval rf = new RandomForestRegressor()<br>\n  .setLabelCol(\"label\")<br>\n  .setFeaturesCol(\"indexedFeatures\")<br>\n<br>\n// Chain indexer and forest in a Pipeline.<br>\nval pipeline = new Pipeline()<br>\n  .setStages(Array(featureIndexer, rf))<br>\n<br>\n// Train model. This also runs the indexer.<br>\nval model = pipeline.fit(trainingData)<br>\n<br>\n// Make predictions.<br>\nval predictions = model.transform(testData)<br>\n<br>\n// Select example rows to display.<br>\npredictions.select(\"prediction\", \"label\", \"features\").show(5)<br>\n<br>\n// Select (prediction, true label) and compute test error.<br>\nval evaluator = new RegressionEvaluator()<br>\n  .setLabelCol(\"label\")<br>\n  .setPredictionCol(\"prediction\")<br>\n  .setMetricName(\"rmse\")<br>\nval rmse = evaluator.evaluate(predictions)<br>\nprintln(s\"Root Mean Squared Error (RMSE) on test data = $rmse\")<br>\n<br>\nval rfModel = model.stages(1).asInstanceOf[RandomForestRegressionModel]<br>\nprintln(s\"Learned regression forest model:\\n ${rfModel.toDebugString}\")<br>",      "type": "ml-estimator",      "nodeClass": "fire.nodes.ml.NodeRandomForestRegression",      "x": "678.969px",      "y": "98.9766px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "featuresCol",          "value": "vectoruid",          "widget": "variable",          "title": "Features Column",          "description": "Features column of type vectorUDT for model fitting",          "datatypes": [            "vectorudt"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "labelCol",          "value": "Weekly_Sales",          "widget": "variable",          "title": "Label Column",          "description": "The label column for model fitting",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "predictionCol",          "value": "",          "widget": "textfield",          "title": "Prediction Column",          "description": "The prediction column created during model scoring.",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "featureSubsetStrategy",          "value": "auto",          "widget": "array",          "title": "Feature Subset Strategy",          "description": "The number of features to consider for splits at each tree node.",          "optionsArray": [            "auto",            "onethird",            "sqrt",            "log2"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "impurity",          "value": "variance",          "widget": "array",          "title": "Impurity",          "description": "The Criterion used for information gain calculation",          "optionsArray": [            "variance"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxBins",          "value": "32",          "widget": "textfield",          "title": "Max Bins",          "description": "The maximum number of bins used for discretizing continuous features.Must be >= 2 and >= number of categories in any categorical feature.",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxDepth",          "value": "5",          "widget": "textfield",          "title": "Max Depth",          "description": "The Maximum depth of a tree",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "minInfoGain",          "value": "0.0",          "widget": "textfield",          "title": "Min Information Gain",          "description": "The Minimum information gain for a split to be considered at a tree node",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "minInstancesPerNode",          "value": "1",          "widget": "textfield",          "title": "Min Instances Per Node",          "description": "The Minimum number of instances each child must have after split",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "numTrees",          "value": "20",          "widget": "textfield",          "title": "Num Trees",          "description": "The number of trees to train",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "subsamplingRate",          "value": "1.0",          "widget": "textfield",          "title": "Subsampling Rate",          "description": "The fraction of the training data used for learning each decision tree.",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "seed",          "value": "",          "widget": "textfield",          "title": "Seed",          "description": "The random seed",          "datatypes": [            "long"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "cacheNodeIds",          "value": "false",          "widget": "array",          "title": "Cache Node Ids",          "description": "The caching nodes IDs. Can speed up training of deeper trees.",          "datatypes": [            "boolean"          ],          "optionsArray": [            "false",            "true"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "checkpointInterval",          "value": "10",          "widget": "textfield",          "title": "Checkpoint Interval",          "description": "The checkpoint interval. E.g. 10 means that the cache will get checkpointed every 10 iterations.Set checkpoint interval (>= 1) or disable checkpoint (-1)",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxMemoryInMB",          "value": "256",          "widget": "textfield",          "title": "Max memory",          "description": "Maximum memory in MB allocated to histogram aggregation.",          "datatypes": [            "integer"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "gridSearch",          "value": "",          "widget": "tab",          "title": "Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "minInfoGainGrid",          "value": "",          "widget": "textfield",          "title": "Min Info Gain Grid Search",          "description": "Min Info Gain Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxBinsGrid",          "value": "",          "widget": "textfield",          "title": "Max Bins Grid Search",          "description": "Max Bins for Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "maxDepthGrid",          "value": "",          "widget": "textfield",          "title": "Max Depth Grid Search",          "description": "Regularization Parameters for Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "numTreesGrid",          "value": "",          "widget": "textfield",          "title": "Num Trees Grid Search",          "description": "Number of trees for Grid Search",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "11",      "name": "Regression Evaluator",      "description": "Evaluator for regression, which expects two input columns: prediction and label.",      "details": "Evaluator for regression, which expects two input columns: prediction and label.<br>\n<br>\nMore details are available at Apache Spark ML docs page:<br>\n<br>\n<a href=\"https://spark.apache.org/docs/latest/api/java/org/apache/spark/ml/evaluation/RegressionEvaluator.html\" target=\"_blank\">spark.apache.org/docs/latest/api/java/org/apache/spark/ml/evaluation/RegressionEvaluator.html</a><br>",      "examples": "",      "type": "ml-evaluator",      "nodeClass": "fire.nodes.ml.NodeRegressionEvaluator",      "x": "896px",      "y": "340px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "labelCol",          "value": "Weekly_Sales",          "widget": "variable",          "title": "Label Column",          "description": "The label column for model fitting.",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "predictionCol",          "value": "prediction",          "widget": "variable",          "title": "Prediction Column",          "description": "The prediction column.",          "datatypes": [            "double"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "metricName",          "value": "r2",          "widget": "array",          "title": "Metric Name",          "description": "The metric used in evaluation.",          "optionsArray": [            "rmse",            "mse",            "r2",            "mae"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "scala"    },    {      "id": "12",      "name": "Drop Rows With Null",      "description": "This node creates a new DataFrame by dropping rows containing null values",      "details": "This node creates a new DataFrame by dropping rows containing NULL values in any of the columns.<br>",      "examples": "Incoming Dataframe has following rows:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE05       |    MARK        |               |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE03       |    TONY        |    MARKETING  |    <br>\nE04       |    MARTIN      |    MARKETING  |    45<br>\n<br>\nIncoming Dataframe has NULL values for two rows. <br>\nUsing DropRowsWithNull node would result in below outgoing Dataframe created by dropping rows having NULL values in any of the columns:<br>\n<br>\nEMP_CD    |    EMP_NAME    |    DEPT       |    AGE<br>\n-------------------------------------------------------<br>\nE01       |    DAVID       |    HR         |    25<br>\nE02       |    JOHN        |    SALES      |    35<br>\nE04       |    MARTIN      |    MARKETING  |    45<br>",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeDropRowsWithNull",      "x": "198.977px",      "y": "73.9766px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "13",      "name": "Spark ML Model Save",      "description": "This node saves the ML model generated at the specified path",      "details": "",      "examples": "",      "type": "ml-modelsave",      "nodeClass": "fire.nodes.ml.NodeModelSave",      "x": "964px",      "y": "95px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "path",          "value": "modelsavepath",          "widget": "textfield",          "title": "Path",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "overwrite",          "value": "false",          "widget": "boolean",          "title": "Overwrite Output",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "14",      "name": "Save predictions",      "description": "Saves the DataFrame into the specified location in CSV Format",      "details": "This node saves incoming Dataframe into the specified location in CSV format.<br>",      "examples": "",      "type": "transform",      "nodeClass": "fire.nodes.save.NodeSaveCSV",      "x": "1079px",      "y": "222px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "path",          "value": "/home/sparkflows/fire-data/data/prediction",          "widget": "textfield",          "title": "Path",          "description": "Path where to save the CSV files",          "required": true,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "saveMode",          "value": "Append",          "widget": "array",          "title": "Save Mode",          "description": "Whether to Append, Overwrite or Error if the path Exists",          "optionsArray": [            "Append",            "Overwrite",            "ErrorIfExists",            "Ignore"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "header",          "value": "false",          "widget": "array",          "title": "Header",          "description": "Should a Header Row be saved with each File?",          "optionsArray": [            "true",            "false"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "advanced",          "value": "",          "widget": "tab",          "title": "Advanced",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "partitionColNames",          "value": "[]",          "widget": "variables",          "title": "Partition Column Names",          "description": "Partition Column Names",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "15",      "name": "Drop Columns",      "description": "This node creates a new DataFrame by dropping the specified columns",      "details": "This node creates a new DataFrame by deleting columns specified as an input.<br>\n<br>\nThe specified columns are dropped from the incoming DataFrame to generate the output DataFrame.<br>",      "examples": "If incoming Dataframe has following columns<br>\n<br>\n<ul>\n<li> CUST_CD</li>\n<li> CUST_NAME</li>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>\nand [DOB] and [ADDRESS] need to be dropped from outgoing Dataframe then add following to the Drop list in the Drop Column node:<br>\n<br>\n<ul>\n<li> DOB</li>\n<li> ADDRESS</li>\n</ul>",      "type": "transform",      "nodeClass": "fire.nodes.etl.NodeDropColumns",      "x": "890px",      "y": "228px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "dropCols",          "value": "[\"vectoruid\"]",          "widget": "variables",          "title": "Columns",          "description": "The columns to be excluded from the output DataFrame",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "16",      "name": "Sticky Note",      "description": "Allows capturing Notes on the Workflow",      "details": "",      "examples": "",      "type": "sticky",      "nodeClass": "fire.nodes.doc.NodeStickyNote",      "x": "95px",      "y": "314px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "bgColor",          "value": "gray",          "widget": "textfield",          "title": "Bg Color",          "description": "Background of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "width",          "value": "300px",          "widget": "textfield",          "title": "Width",          "description": "Width of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "height",          "value": "110px",          "widget": "textfield",          "title": "Height",          "description": "Height of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "comment",          "value": "<p><span style=\"background-color: rgb(248, 249, 250); color: rgb(0, 0, 0);\">Link to Notebook: </span><a href=\"https://www.kaggle.com/code/shubhamsinghgharsele/retail-data-analysis/notebook\" rel=\"noopener noreferrer\" target=\"_blank\" style=\"background-color: rgb(248, 249, 250);\">https://www.kaggle.com/code/shubhamsinghgharsele/retail-data-analysis/notebook</a></p>",          "widget": "textarea_rich",          "title": "Comment",          "description": "Comments for the Workflow",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    },    {      "id": "17",      "name": "Sticky Note",      "description": "Allows capturing Notes on the Workflow",      "details": "",      "examples": "",      "type": "sticky",      "nodeClass": "fire.nodes.doc.NodeStickyNote",      "x": "35px",      "y": "456px",      "fields": [        {          "name": "storageLevel",          "value": "DEFAULT",          "widget": "array",          "title": "Output Storage Level",          "description": "Storage Level of the Output Datasets of this Node",          "optionsArray": [            "DEFAULT",            "NONE",            "DISK_ONLY",            "DISK_ONLY_2",            "MEMORY_ONLY",            "MEMORY_ONLY_2",            "MEMORY_ONLY_SER",            "MEMORY_ONLY_SER_2",            "MEMORY_AND_DISK",            "MEMORY_AND_DISK_2",            "MEMORY_AND_DISK_SER",            "MEMORY_AND_DISK_SER_2",            "OFF_HEAP"          ],          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "bgColor",          "value": "blue",          "widget": "textfield",          "title": "Bg Color",          "description": "Background of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "width",          "value": "629px",          "widget": "textfield",          "title": "Width",          "description": "Width of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "height",          "value": "163px",          "widget": "textfield",          "title": "Height",          "description": "Height of note",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        },        {          "name": "comment",          "value": "<h2>Dataset</h2><p><br></p><p>Input dataset is store wise weekly data</p><p><br></p><p><br></p><p>Output is to predict the weekly sales for every store</p>",          "widget": "textarea_rich",          "title": "Comment",          "description": "Comments for the Workflow",          "required": false,          "display": true,          "editable": true,          "disableRefresh": false        }      ],      "engine": "all"    }  ],  "edges": [    {      "source": "1",      "target": "2",      "id": 1    },    {      "source": "2",      "target": "3",      "id": 2    },    {      "source": "4",      "target": "5",      "id": 3    },    {      "source": "7",      "target": "9",      "id": 4    },    {      "source": "5",      "target": "10",      "id": 5    },    {      "source": "5",      "target": "7",      "id": 6    },    {      "source": "10",      "target": "7",      "id": 7    },    {      "source": "7",      "target": "11",      "id": 8    },    {      "source": "3",      "target": "12",      "id": 9    },    {      "source": "12",      "target": "4",      "id": 10    },    {      "source": "10",      "target": "13",      "id": 11    },    {      "source": "7",      "target": "15",      "id": 12    },    {      "source": "15",      "target": "14",      "id": 13    }  ],  "dataSetDetails": [],  "engine": "scala"}
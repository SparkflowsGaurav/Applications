{	"name": "Pipe Python with Pandas",	"uuid": "6039be1f-a3e1-41de-9ab1-3a7f1ef7f046",	"category": "Python",	"description": "-",	"parameters": "-",	"nodes": [		{			"id": "1",			"name": "DatasetStructured",			"description": "This Node creates a DataFrame by reading data from HDFS, HIVE etc. The dataset has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.",			"details": "This Node creates a DataFrame by reading data from HDFS, HIVE etc.<br>\n<br>\nThe data has been defined earlier in Fire by using the Dataset Feature. As a user, you just have to select the Dataset of your interest.<br>",			"examples": "",			"type": "dataset",			"nodeClass": "fire.nodes.dataset.NodeDatasetStructured",			"x": "140.5px",			"y": "117.667px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "dataset",					"value": "68d15f1c-60ca-48fd-bea3-064820bd8815",					"widget": "dataset",					"title": "Dataset",					"description": "Selected Dataset",					"required": true,					"display": true,					"editable": true,					"disableRefresh": false				}			]		},		{			"id": "2",			"name": "Pipe Python2",			"description": "This node runs any given Python code. It pipes the incoming DataFrame through pipe to the Python Script. Output back to Spark has to be written out using print.",			"details": "",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.etl.NodePipePython2",			"x": "439.5px",			"y": "121.667px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "codeHeader",					"value": "#!/usr/bin/python\n\nimport sys\nimport pandas as pd\n\ndataframe_list_of_rows = []\n\nfor line in sys.stdin:\n\n    line = line.strip()\n    if not line:\n        continue\n\n    row_list = []\n    for field in line.split(\",\"):\n        row_list.append(field)\n\n    # convert list to tuple\n    row_tuple = tuple(row_list)\n    dataframe_list_of_rows.append(row_tuple)\n\n\n# generate column names\nschema = sys.argv[1]\ncolumn_names = []\nschema_columns = schema.split(\"|\")\nfor column_name_with_type in schema_columns:\n    column_name_with_type_split = column_name_with_type.split(\":\")\n    column_names.append(column_name_with_type_split[0])\n\n# create dataframe from the input rows\ninput_dataframe = pd.DataFrame.from_records(dataframe_list_of_rows, columns=column_names)\n\n",					"widget": "textarea_small",					"title": "Pipe Header Code",					"description": "Header part of the Python code to be run. It receives each record as a string",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "codeBody",					"value": "output_dataframe = input_dataframe\n\n",					"widget": "textarea_large",					"title": "Pipe Body Code",					"description": "Body part of the Python code to be run.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "codeFooter",					"value": "# output the output_dataframe dtypes to the provided file name\n\ndataframe_dtypes = output_dataframe.dtypes\n\nf = open(sys.argv[2],'w+')\nf.write(str(dataframe_dtypes))\nf.close()\n\n\n# iterate over the dataframe created and return it to the pipeNode\nfor index, row in output_dataframe.iterrows():\n  list = row.tolist()\n  row_string = ','.join(str(e) for e in list)\n  print(row_string)\n            ",					"widget": "textarea_small",					"title": "Pipe Footer Code",					"description": "Footer part of the Python code to be run. It should write out each resulting record back as a string.",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColNames",					"value": "[\"c1\",\"c2\",\"c3\",\"c4\"]",					"widget": "schema_col_names",					"title": "Output Column Names",					"description": "Output Schema of Pipe Python Processor",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColTypes",					"value": "[\"STRING\",\"STRING\",\"STRING\",\"STRING\"]",					"widget": "schema_col_types",					"title": "Output Column Types",					"description": "Data Type of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "outputColFormats",					"value": "[\"\",\"\",\"\",\"\"]",					"widget": "schema_col_formats",					"title": "Output Column Formats",					"description": "Format of the Output Columns",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			]		},		{			"id": "3",			"name": "PrintNRows",			"description": "Prints the specified number of records in the DataFrame. It is useful for seeing intermediate output",			"details": "",			"examples": "",			"type": "transform",			"nodeClass": "fire.nodes.util.NodePrintFirstNRows",			"x": "778.5px",			"y": "120.667px",			"fields": [				{					"name": "storageLevel",					"value": "DEFAULT",					"widget": "array",					"title": "Output Storage Level",					"description": "Storage Level of the Output Datasets of this Node",					"optionsArray": [						"DEFAULT",						"NONE",						"DISK_ONLY",						"DISK_ONLY_2",						"MEMORY_ONLY",						"MEMORY_ONLY_2",						"MEMORY_ONLY_SER",						"MEMORY_ONLY_SER_2",						"MEMORY_AND_DISK",						"MEMORY_AND_DISK_2",						"MEMORY_AND_DISK_SER",						"MEMORY_AND_DISK_SER_2",						"OFF_HEAP"					],					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "title",					"value": "Row Values",					"widget": "textfield",					"title": "Title",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				},				{					"name": "n",					"value": "10",					"widget": "textfield",					"title": "Num Rows to Print",					"description": "number of rows to be printed",					"required": false,					"display": true,					"editable": true,					"disableRefresh": false				}			]		}	],	"edges": [		{			"source": "1",			"target": "2",			"id": 1		},		{			"source": "2",			"target": "3",			"id": 2		}	],	"dataSetDetails": [		{			"id": 45,			"uuid": "68d15f1c-60ca-48fd-bea3-064820bd8815",			"header": true,			"path": "data/cars.csv",			"delimiter": ",",			"datasetType": "CSV",			"datasetSchema": "{\"colNames\":[\"c1\",\"c2\",\"c3\",\"c4\"],\"colTypes\":[\"DOUBLE\",\"DOUBLE\",\"DOUBLE\",\"DOUBLE\"],\"colFormats\":[\"\",\"\",\"\",\"\"],\"colMLTypes\":[\"NUMERIC\",\"NUMERIC\",\"NUMERIC\",\"NUMERIC\"]}"		}	]}